
\newcommand{\semrec}{\AR{Semantics}}
\newcommand{\semfun}{\AF{semantics}}

\section{Introduction}

In modern typed programming languages, programmers writing embedded
Domain-Specific Languages (DSLs)~\cite{hudak1996building} and researchers formalising them can now
use the host language's type system to help them. Using Generalised
Algebraic Data Types (GADTs) or the more general indexed families of
Type Theory~\cite{dybjer1994inductive} to represent syntax,
programmers can \emph{statically} enforce some of the invariants in
their languages. For example, managing variable scope is a popular use
case in LEGO, Idris, Coq, Agda and
Haskell~\cite{altenkirch1999monadic,DBLP:conf/gpce/BradyH06,DBLP:journals/jar/HirschowitzM12,DBLP:conf/icfp/KeuchelJ12,BachPoulsen,plfa2018,Eisenberg20}
as directly manipulating raw de Bruijn indices is notoriously
error-prone. Solutions have been proposed that range from enforcing
well-scopedness of variables to ensuring full type correctness. In
short, these techniques use the host languages' types to ensure that
``illegal states are unrepresentable'', where illegal states
correspond to ill scoped or ill typed terms in the object language.

Despite the large body of knowledge in how to use types to define well
formed syntax (see the related work in Section
\ref{section:related-work}), it is still necessary for the working DSL
designer or formaliser to redefine essential functions like renaming
and substitution for each new syntax, and then to reprove essential
lemmas about those functions. To reduce the burden of such repeated
work and boilerplate, in this paper we apply the methodology of
data type genericity to programming and proving with syntaxes with
binding.

To motivate our approach, let us look at the formalisation of an
apparently straightforward program transformation: the inlining of
let-bound variables by substitution together with a soundness lemma
proving that reductions in the source languages can be simulated by
reductions in the target one. There are two languages: the source
(\AD{S}), which has let-bindings, and the target (\AD{T}), which only
differs in that it does not:
\begin{displaymath}
  \AD{S} ::= x \mid \AD{S}~\AD{S} \mid \lambda x. \AD{S} \mid \textrm{let }x=\AD{S}\textrm{ in }\AD{S}
  \qquad
  \AD{T} ::= x \mid \AD{T}~\AD{T} \mid \lambda x. \AD{T}
\end{displaymath}

Breaking the task down, an implementer needs to define an operational
semantics for each language, define the program transformation itself,
and prove a correctness lemma that states each step in the source
language is simulated by zero or more steps of the transformed terms
in the target language. In the course of doing this, they will
discover that there is actually a large amount of work:

\begin{enumerate}
\item To define the operational semantics, one needs to define
  substitution, and hence renaming. This needs to be done separately
  for both the source and target languages, even though they are very
  similar;
\item In the course of proving the correctness lemma, one needs to
  prove eight lemmas about the interactions of renaming, substitution,
  and transformation that are all remarkably similar, but must be
  stated and proved separately (e.g, as observed by Benton, Hur, Kennedy
  and McBride~\citeyear{benton2012strongly}).
\end{enumerate}

Even after doing all of this work, they have only a result for a single
pair of source and target languages. If they were to change their
languages $\AD{S}$ or $\AD{T}$, they would have to repeat the same work
all over again (or at least do a lot of cutting, pasting, and
editing).
% The cases for λs and applications in the
% transformation are structural, but if we add more constructs to both
% languages, we would have to write more and more code to say we are
% doing nothing interesting to them.

The main contribution of this paper is that by using the universe of
syntaxes with binding we present in this paper, we are able to solve
this repetition problem \emph{once and for all}.

%  For
% \emph{every} syntax in our universe, we are able to generically define
% renaming and substitution \ref{section:renandsub}, generically define
% the let-binding removal transformation \ref{section:letbinding}, and
% generically prove the required renaming, substitution and
% transformation fusion lemmas (\ref{section:fusion}.

\paragraph*{Content and Contributions}
To introduce the basic ideas that this paper builds on, we start with
primers on scoped and sorted terms
(Section~\ref{section:primer-term}), scope- and sort-safe programs
acting on them (Section~\ref{section:primer-program}), and
programmable descriptions of data types (Section~\ref{section:data}).
These introductory sections help us build an understanding of the
problem at hand as well as a toolkit that leads us to the novel
content of this paper: a universe of scope-safe syntaxes with binding
(Section~\ref{section:universe}) together with a notion of scope-safe
semantics for these syntaxes (Section~\ref{section:semantics}).  This
gives us the opportunity to write generic implementations of renaming
and substitution (Section~\ref{section:renandsub}), a generic
let binding removal transformation (generalising the problem stated
above) (Section~\ref{section:letbinding}), and normalisation by
evaluation (Section~\ref{section:nbyeval}). Further, we show how to
construct generic proofs by formally describing what it means for one
semantics to simulate another (Section~\ref{section:simulation}), or
for two semantics to be fusible (Section~\ref{section:fusion}). This
allows us to prove the lemmas required above for renaming,
substitution, and desugaring of let binders generically, for
\emph{every} syntax in our universe.

\medskip

Our implementation language is
Agda~\cite{norell2009dependently}. However, our techniques are
language independent: any dependently typed language at least as
powerful as Martin-L\"of Type Theory~\cite{martin1982constructive}
equipped with inductive families~\cite{dybjer1994inductive} such as
Coq~\cite{Coq:manual}, Lean~\cite{DBLP:conf/cade/MouraKADR15} or
Idris~\cite{brady2013idris} ought to do.

\medskip

\paragraph*{Changes with respect to the ICFP 2018 version} This paper
is a revised and expanded version of a paper of the same title that
appeared at ICFP 2018. This extended version of the paper includes
many more examples of the use of our universe of syntax with binding
for writing generic programs in Section~\ref{section:catalogue}:
pretty printing with human readable names
(Section~\ref{section:genericprinting}), scope checking
(Section~\ref{section:genericscoping}), type checking
(Section~\ref{section:typechecking}), elaboration
(Section~\ref{section:elaboration}), inlining of single use let-bound
expressions (shrinking reductions) (Section~\ref{section:inlining}),
and normalisation by evaluation (Section~\ref{section:nbyeval}). We
have also included a discussion of how to define generic programs for
deciding equality of terms. Additionally, we have elaborated our
descriptions and examples throughout, and expanded our discussion of
related work in Section~\ref{section:related-work}.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% SCOPE SAFE TERMS


\section{A primer on scope- and sort-safe terms}\label{section:primer-term}

\paragraph*{From inductive types to inductive families for abstract
  syntax} A reasonable way to represent the abstract syntax of the
untyped $\lambda$-calculus in a typed functional programming language
is to use an inductive type:
\begin{displaymath}
  \begin{array}{l}
    \AK{data}\;\AD{Lam} : \AD{Set}\;\AK{where} \\
    \quad\begin{array}{@{}lll}
           \AIC{`var} &:& \AD{ℕ} \to \AD{Lam} \\
           \AIC{`lam} &:& \AD{Lam} \to \AD{Lam} \\
           \AIC{`app} &:& \AD{Lam} \to \AD{Lam} \to \AD{Lam}
    \end{array}
  \end{array}
\end{displaymath}
We have used de Bruijn~\citeyear{de1972lambda} indices to represent
variables by the number of $\mathsf{`lam}$ binders one has to pass up
through to reach the binding occurrence. The de Bruijn representation
has the advantage that terms are automatically represented up to
$\alpha$-equivalence. If the index goes beyond the number of binders
enclosing it, then we assume that it is referring to some context,
left implicit in this representation.

This representation works well enough for writing programs, but the
programmer must constantly be vigilant to guard against the accidental
construction of ill scoped terms. The implicit context that
accompanies each represented term is prone to being forgotten or
muddled with another, leading to confusing behaviour when variables
either have dangling pointers or point to the wrong thing.

To improve on this situation, previous authors have proposed to use
the host language's type system to make the implicit context explicit,
and to enforce well-scopedness of variables. Scope-safe terms follow
the discipline that every variable is either bound by some binder or
is explicitly accounted for in a context. Bellegarde and
Hook~\citeyear{BELLEGARDE1994287}, Bird and
Paterson~\citeyear{bird_paterson_1999}, and Altenkirch and
Reus~\citeyear{altenkirch1999monadic} introduced the classic
presentation of scope safety using inductive
\emph{families}~\cite{dybjer1994inductive} instead of plain inductive
types to represent abstract syntax. Indeed, using a family indexed by
a $\Set{}$, we can track scoping information at the type level. The
empty $\Set$ represents the empty scope. The type constructor
$1 + (\_)$ extends the running scope with an extra variable.
\begin{displaymath}
  \begin{array}{l}
    \AK{data}\;\AD{Lam} : \AD{Set} \to \AD{Set}\;\AK{where} \\
    \quad\begin{array}{@{}lll}
           \AIC{`var} &:& \AB{X} \to \AD{Lam}\;\AB{X} \\
           \AIC{`lam} &:& \AD{Lam}\;(\AD{1+} \AB{X}) \to \AD{Lam}\;\AB{X} \\
           \AIC{`app} &:& \AD{Lam}\;\AB{X} \to \AD{Lam}\;\AB{X} \to \AD{Lam}\;\AB{X}
    \end{array}
  \end{array}
\end{displaymath}

\paragraph*{Implicit generalisation of variables in Agda} The careful
reader may have noticed that we use a seemingly out-of-scope variable
\AB{X} of type \AF{Set}. The latest version of Agda allows us to declare
variables that the system should implicitly quantify over if it happens
to find them used in types. This allows us to lighten the presentation
by omitting a large number of prenex quantifiers. The reader will hopefully
be familiar enough with prenex polymorphic types in the style of Standard ML \cite{defnsml} that this will
seem natural to them.


The \AD{Lam} type is now a family of types, indexed by the set
of variables in scope. Thus, the context for each represented term has
been made visible to the type system, and the types enforce that only
variables that have been explicitly declared can be referenced in the
\AIC{`var} constructor. We have made illegal terms
unrepresentable.


% An inductive type is the fixpoint of an endofunctor on $\Set{}$.
% Similarly, an inductive family is the fixpoint of an endofunctor on
% $\Set \to \Set$. Using inductive families to enforce scope safety, we
% get the following definition of the untyped λ-calculus: $T(F)
% = \lambda X \!\in\! \Set{}.\; X + (F(X) \times F(X)) + F(1 + X)$.
% This endofunctor offers a choice of three constructors.  The first one
% corresponds to the variable case; it packages an inhabitant of $X$,
% the index $\Set{}$. The second corresponds to an application node;
% both the function and its argument live in the same scope as the
% overall expression. The third corresponds to a λ-abstraction;
% it extends the current scope with a fresh variable.  The language is
% obtained as the fixpoint of $T$:
% \[
%    \mathit{Lam} = \mu F \in \Set{}^{\Set{}}.
%    \lambda X \!\in\! \Set{}.\; X + (F(X) \times F(X)) + F(1 + X)
% \]
Since \AD{Lam} is defined to be a function $\AD{Set} \to \AD{Set}$, it
makes sense to ask whether it is also a functor and a monad. Indeed it
is, as Altenkirch and Reus showed. The functorial action corresponds
to renaming, the monadic ``return'' corresponds to the use of variables
(the \AIC{`var} constructor), and the monadic ``bind'' corresponds
to substitution. The functor and monad laws correspond to well known
properties from the equational theories of renaming and
substitution. We will revisit these properties, for our whole universe
of syntax with binding, in Section~\ref{section:fusion}.

\paragraph*{A Typed Variant of Altenkirch and Reus' Calculus}
\label{section:mech-reus}

There is no reason to restrict this technique to inductive families
indexed by $\Set{}$. The more general case of inductive families in
$\Set{}^J$ can be endowed with similar functorial and monadic
operations by using Altenkirch, Chapman and Uustalu's relative
monads~\citeyear{Altenkirch2010, JFR4389}.

We pick as our index type $J$ the category whose objects are
inhabitants of \AD{List} \AB{I} (\AB{I} is a parameter of the
construction) and whose morphisms are thinnings (permutations that may
forget elements, we give the definition in Section~\ref{sec:genenvironment}).  Values of type
\AD{List} \AB{I} are intended to represent the list of the sorts (or
kinds, or types, depending on the application) of the de Bruijn
variables in scope. We can recover an unsorted approach by picking $I$
to be the unit type.  Given this sorted setting, our functors take an
extra $I$ argument corresponding to the sort of the expression being
built. This is captured by the large type \AB{I}
\AF{─Scoped}:% = $I$ $\to$ \AD{List} $I$ $\to$ \AF{Set}.

\begin{agdasnippet}
\ExecuteMetaData[Data/Var.tex]{scoped}
\end{agdasnippet}
%
We use Agda's mixfix operator notation, where underscores denote
argument positions.

To lighten the presentation, we exploit the observation that the
current scope is either passed unchanged to subterms (e.g. in the
application case) or extended (e.g. in the λ-abstraction case) by
introducing combinators to build indexed types. We conform to the
convention (see e.g.~\citet{martin1982constructive}) of mentioning
only context \emph{extensions} when presenting judgements.
That is
to say that we aim to write sequents with an \emph{implicit} ambient
context. Concretely: in the simply typed
$\lambda$-calculus (STLC) we would rather use the rule \AB{appᵢ} than
\AB{appₑ} as the inference rule for application.

\begin{mathpar}
\inferrule{f : σ → τ \and t : σ}
 {f\,t : τ}
 {appᵢ}
\and
\inferrule{Γ ⊢ f : σ → τ \and Γ ⊢ t : σ}
 {Γ ⊢ f\,t : τ}
 {appₑ}
\end{mathpar}

In this discipline, the turnstile is used in rules which are binding
fresh variables. It separates the \emph{extension} applied to the ambient
context on its left and the judgment that lives in the thus extended
context on its right. Concretely: we would rather use the rule \AB{lamᵢ}
than \AB{lamₑ} as the inference rule for λ-abstraction in STLC.

\begin{mathpar}
\inferrule{x:σ ⊢ b : τ}
 {λx.t : σ → τ}
 {lamᵢ}
\and
\inferrule{Γ, x:σ ⊢ b : τ}
 {Γ ⊢ λx.t : σ → τ}
 {lamₑ}
\end{mathpar}

This observation that an ambient context is either passed around as is
or extended for subterms is critical to our whole approach to syntax
with binding, and will arise again in our generic formulation of
syntax traversals in Section~\ref{section:semantics}. To facilitate
this, we make use of the following combinators for building indexed
sets:
% All the definitions are polymorphic in the index type
% (called \AB{A} in Figure~\ref{figure:indexed}).

\noindent
\begin{minipage}{\textwidth}
  \begin{minipage}{0.5\textwidth}
    \ExecuteMetaData[Stdlib.tex]{arrow}
  \end{minipage}\hfill
  \begin{minipage}{0.5\textwidth}
    \ExecuteMetaData[Stdlib.tex]{adjust}
  \end{minipage}
\end{minipage}

\noindent
\begin{minipage}{\textwidth}
  \begin{minipage}{0.5\textwidth}
    \ExecuteMetaData[Stdlib.tex]{constant}
  \end{minipage}\hfill
  \begin{minipage}{0.5\textwidth}
    \ExecuteMetaData[Stdlib.tex]{forall}
  \end{minipage}
\end{minipage}

We lift the function space pointwise with \AF{\_⇒\_}, silently
threading the underlying scope. The \AF{\_⊢\_} makes explicit the
\emph{adjustment} made to the index by a function, a generalisation
of the idea of \emph{extension}. We write \AB{f}
\AF{⊢} \AB{T} where \AB{f} is the adjustment and \AB{T} the indexed
Set it operates on. Although it may seem surprising at first to define
binary infix operators as having arity three, they are meant to be
used partially applied, surrounded by \AF{∀[\_]} which turns an
indexed Set into a Set by implicitly quantifying over the index.
Lastly, \AF{const} is the constant combinator, which ignores the
index.

We make \AF{\_⇒\_} associate to the right as one would expect and give it the
highest precedence level as it is the most used combinator. These combinators
lead to more readable type declarations.  For instance, the compact expression
\AF{∀[} (\AF{const} \AB{P} \AF{⇒} \AIC{s} \AF{⊢} \AB{Q}) \AF{⇒} \AB{R} \AF{]}
desugars to the more verbose type
\AS{∀} \{\AB{i}\} \AS{→} (\AB{P} \AS{→} \AB{Q} (\AIC{s} \AB{i})) \AS{→} \AB{R} \AB{i}.

As the context argument comes second in the definition of
\AF{\_─Scoped}, we can readily use these combinators to thread,
modify, or quantify over the scope when defining such families, as for
example in this data type for scope- and sort-aware de Bruijn indices:
%Figure~\ref{fig:Var}.

\begin{agdasnippet}
  \ExecuteMetaData[Data/Var.tex]{var}
  %\caption{Scope and Kind Aware de Bruijn Indices\label{fig:Var}}
\end{agdasnippet}

The inductive family \AD{Var} represents well scoped and well sorted
de Bruijn indices. Its \AIC{z} (for zero) constructor refers to the
nearest binder in a non-empty scope. The \AIC{s} (for successor)
constructor lifts a a variable in a given scope to the extended scope
where an extra variable has been bound. Both of the constructors'
types have been written using the combinators defined above.  They
respectively normalise to:
\begin{center}
  \AIC{z} : {\AS{∀} \{\AB{σ} \AB{Γ}\}
            \AS{→} \AD{Var} \AB{σ} (\AB{σ} \AIC{::} \AB{Γ})}
  \qquad
  \AIC{s} : {\AS{∀} \{\AB{σ} \AB{τ} \AB{Γ}\}
            \AS{→} \AD{Var} \AB{σ} \AB{Γ}
            \AS{→} \AD{Var} \AB{σ} (\AB{τ} \AIC{::} \AB{Γ})}
\end{center}
We will reuse the \AD{Var} family to represent variables in all the
syntaxes defined in this paper. We start with the simply typed
$\lambda$-calculus (STLC):

\noindent
\begin{minipage}{0.99\textwidth}
  \begin{minipage}[t]{0.4\textwidth}
    \ExecuteMetaData[StateOfTheArt/ACMM.tex]{type}
  \end{minipage}
  \begin{minipage}[t]{0.59\textwidth}
    \ExecuteMetaData[StateOfTheArt/ACMM.tex]{tm}
  \end{minipage}
% \caption{Simple Types and Intrinsically Typed definition of STLC}
% \label{fig:intrinsic-stlc}
\end{minipage}

The \AD{Type} \AF{─Scoped} family \AD{Lam} is Altenkirch and Reus'
intrinsically typed representation of the simply typed λ-calculus,
where \AD{Type} is the Agda type of simple types.  We can readily
write well scoped-and-typed terms such as application, a closed
term of type {((\AB{σ} \AIC{`→} \AB{τ}) \AIC{`→} (\AB{σ} \AIC{`→}
  \AB{τ}))} (\AC{\{-} and \AC{-\}} delimit comments meant to help the
reader see to which binders each de Bruijn index refers):

\begin{agdasnippet}
  \ExecuteMetaData[StateOfTheArt/ACMM.tex]{apply}
\end{agdasnippet}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% SCOPE SAFE PROGRAMS


\section{A primer on type- and scope-safe programs}\label{section:primer-program}

The type- and scope-safe representation described in the previous
section is naturally only a start. Once the programmer has access to a
good representation of the language they are interested in, they will
want to write programs manipulating terms.  Renaming and substitution
are the two typical examples that are required for almost all
syntaxes. Now that well-typedness and well-scopedness are enforced
statically, all of these traversals have to be implemented in a type-
and scope-safe manner.  These constraints show up in the types of
renaming and substitution defined as follows:

\noindent
\begin{minipage}{0.99\textwidth}
\begin{minipage}{0.50\textwidth}
\ExecuteMetaData[StateOfTheArt/ACMM.tex]{ren}
\end{minipage}\hfill
\begin{minipage}{0.49\textwidth}
\ExecuteMetaData[StateOfTheArt/ACMM.tex]{sub}
\end{minipage}
% \caption{Type and Scope Preserving Renaming and Substitution}
% \label{figure:rensubACMM}
\end{minipage}

We have intentionally hidden technical details behind some auxiliary definitions
left abstract here: \AF{var} and \AF{extend}. Their implementations are distinct
for \AF{ren} and \AF{sub} but they serve the same purpose: \AF{var} is used to
turn a value looked up in the evaluation environment into a term and \AF{extend}
is used to alter the environment when going under a binder. This presentation
highlights the common structure between \AF{ren} and \AF{sub} which we will exploit
later in this section, particularly in Section~\ref{section:lamsem}
where we define an abstract notion of semantics and the corresponding generic traversal.

\subsection{A generic notion of environments}\label{sec:genenvironment}

Both renaming and substitution are defined in terms of \emph{environments}.
We typically call an environment that associates values
to each variable in \AB{Γ} a \AB{Γ}-environment. This informs our notation choice: we write
{((\AB{Γ} \AR{─Env}) \AB{𝓥} \AB{Δ})} for an environment that associates
a value \AB{𝓥} (variables for renaming, terms for substitution) well scoped
and well typed in \AB{Δ} to every entry in \AB{Γ}. Formally, we have the following
record structure (using a record helps Agda's type inference reconstruct the
type family \AB{𝓥} of values for us):

\begin{agdasnippet}
\ExecuteMetaData[Data/Environment.tex]{env}
%\caption{Well Typed and Scoped Environments of Values}\label{fig:environment}
\end{agdasnippet}

%%% 2019-11-12
\paragraph*{Environments as records in Agda}
As with (all) other record structures defined in this paper, we are
able to profit from Agda's \emph{copattern} syntax, as introduced in
\cite{abel2013copatterns} and showcased in \cite{thibodeau2016case}.
That is, when defining an environment \AB{\(\rho\)}, we may either use
the constructor \AIC{pack}, packaging a function \AB{r} as an
environment {\AB{\(\rho\)}~=~\AIC{pack}~\AB{r}}, or else define
\AB{\(\rho\)} in terms of the underlying function obtained from it by
projecting out the (in this case, unique) \ARF{lookup} field, as
{\ARF{lookup}~\AB{\(\rho\)}~=~\AB{r}}. A value of a record type with
more than one field requires each of its fields to be given, either by
a named constructor (or else Agda's default \AK{record} syntax), or in
copattern style. By analogy with record/object syntax in other
languages, Agda further supports `dot' notation, so that an equivalent
definition here could be expressed as
{\AB{\(\rho\)}~.\ARF{lookup}~=~\AB{r}}.
%%%

We can readily define some basic building blocks for environments:

\noindent
\begin{minipage}{0.99\textwidth}
  \centering
  \begin{minipage}[t]{0.3\textwidth}
    \ExecuteMetaData[Data/Environment.tex]{empty}
  \end{minipage}
  \begin{minipage}[t]{0.69\textwidth}
    \ExecuteMetaData[Data/Environment.tex]{extension}
  \end{minipage}
\end{minipage}
\begin{agdasnippet}
  \ExecuteMetaData[Data/Environment.tex]{envmap}
\end{agdasnippet}
The empty environment (\AF{ε}) is implemented
by remarking that there can be no variable of type
{(\AD{Var} \AB{σ} \AIC{[]})} and to correspondingly dismiss the case with
the impossible pattern \AS{()}. The function \AF{\_∙\_} extends an existing
\AB{Γ}-environment with a new value of type \AB{σ} thus returning a
{(\AB{σ} \AIC{∷} \AB{Γ})}-environment. We also include the definition
of \AF{\_<\$>\_}, which lifts in a pointwise manner a function acting
on values into a function acting on environment of such values.

As we have already observed, the definitions of renaming and substitution have very
similar structure. Abstracting away this shared structure would allow for these
definitions to be refactored, and their common properties to be proved in one swift
move.

Previous efforts in dependently typed
programming~\cite{benton2012strongly,allais2017type}
have achieved this goal and refactored renaming and substitution,
but also normalisation by evaluation, printing with names or continuation-passing style (CPS) conversion
as various instances of a more general traversal. As we will show in Section~\ref{section:typechecking},
type checking in the style of Atkey~\citeyear{atkey2015algebraic} also
fits in that framework. To make sense of this body of work, we
need to introduce three new notions below: \AF{Thinning}, a generalisation of
renaming; the
\AF{□} functor, which freely adds the ability to absorb \AF{Thinning}s to any indexed type; and \AF{Thinnable}s, which are \AF{□}-coalgebras, i.e., types that permit thinning.
%%%
We use \AF{□}, and our compact notation for the indexed function space
between indexed types, to crisply encapsulate the additional quantification
over environment extensions which is typical of Kripke semantics.
%%%

\paragraph*{The special case of thinnings}~

\begin{agdasnippet}
%  \begin{minipage}{0.5\linewidth}
    \ExecuteMetaData[Data/Environment.tex]{thinning}
%  \end{minipage}
% \caption{Thinnings: A Special Case of Environments}
% \label{def:thinning}
\end{agdasnippet}

\AF{Thinning}s subsume more structured notions such as the Category of
Weakenings~\cite{altenkirch1995categorical} or Order Preserving
Embeddings~\cite{chapman2009type}. In particular, they do not prevent the
user from defining arbitrary permutations or from introducing contractions
although we will not use such instances. However, such extra flexibility
will not get in our way, and permits a representation as a function space
which grants us monoid laws ``for free'' as per Jeffrey's
observation~\citeyear{jeffrey2011assoc}. We define the following identity, extend and (generalised) transitivity combinators for \AF{Thinning}s:

\noindent
\begin{minipage}{0.95\textwidth}
\begin{minipage}{0.45\textwidth}
  \ExecuteMetaData[Data/Environment.tex]{identity}
\end{minipage}
\begin{minipage}{0.45\textwidth}
  \ExecuteMetaData[Data/Environment.tex]{extend}
\end{minipage}
  \ExecuteMetaData[Data/Environment.tex]{select}
%\caption{Identity Thinning, context extension, and (generalised) transitivity}\label{fig:thincomb}
\end{minipage}


Next, the \AF{□} combinator turns any (\AD{List} \AB{I})-indexed Set into one that can
absorb thinnings.

\noindent
\begin{minipage}{0.95\textwidth}
\begin{minipage}{0.45\textwidth}
\ExecuteMetaData[Data/Environment.tex]{box}
\end{minipage}\hfill
\begin{minipage}{0.45\textwidth}
\ExecuteMetaData[Data/Environment.tex]{thinnable}
\end{minipage}

\begin{minipage}{0.26\textwidth}
\ExecuteMetaData[Data/Environment.tex]{extract}
\end{minipage}\hfill
\begin{minipage}{0.37\textwidth}
\ExecuteMetaData[Data/Environment.tex]{duplicate}
\end{minipage}\hfill
\begin{minipage}{0.29\textwidth}
\ExecuteMetaData[Data/Environment.tex]{thBox}
\end{minipage}

%\caption{The \AF{□} comonad, Thinnable, and the cofree Thinnable. \label{fig:Thinnable}}
\end{minipage}
This is accomplished by abstracting over all possible thinnings
from the current scope, akin to an S4-style necessity modality. The axioms of S4
modal logic incite us to observe that the functor \AF{□} is a comonad: \AF{extract}
applies the identity \AF{Thinning} to its argument, and \AF{duplicate} is obtained
by composing the two \AF{Thinning}s we are given. The expected laws hold trivially
thanks to Jeffrey's trick mentioned above.

The notion of \AF{Thinnable} is the property of being stable under thinnings;
in other words \AF{Thinnable}s are the coalgebras of \AF{□}.
It is a crucial property for values to have if one wants to be able to push
them under binders. From the comonadic structure we get that
the \AF{□} combinator freely turns any (\AD{List} I)-indexed Set into a
\AF{Thinnable} one.

\subsection{A Generic Notion of Semantics}

As we showed in Allais, Chapman, McBride and McKinna
\citeyear{allais2017type}, which we will refer to mnemonically as
ACMM, once equipped with these new notions we can define an abstract
concept of semantics for our type- and scope-safe language. Provided
that a set of constraints on two ({\AF{Type} \AF{─Scoped}}) families
\AB{𝓥} and \AB{𝓒} is satisfied, we will obtain a traversal of the
following type:

\begin{agdasnippet}
\ExecuteMetaData[StateOfTheArt/ACMM.tex]{semtype}
\end{agdasnippet}

Broadly speaking, a semantics turns our deeply embedded abstract syntax
trees into the shallow embedding of the corresponding parametrised higher
order abstract syntax term. We get a choice of useful type- and scope-safe
traversals by using different ``host languages'' for this shallow embedding.

Semantics, specified in terms of a record \semrec{}, are defined in terms
of a choice of values \AB{𝓥} and computations \AB{𝓒}. A semantics must
satisfy constraints on the notions of values \AB{𝓥} and computations \AB{𝓒}
at hand.

In the following paragraphs, we interleave the definition of the record
of constraints \semrec{} with explanations of our choices. It is important
to understand that all of the indented Agda snippets are part of the record's
definition. Some correspond to record fields (highlighted in \ARF{pink})
while others are mere auxiliary definitions (highlighted in \AF{blue}) as
permitted by Agda.


\begin{agdasnippet}
\ExecuteMetaData[StateOfTheArt/ACMM.tex]{rsemtype}\label{section:lamsem}
\end{agdasnippet}
First of all, values \AB{𝓥} should be \AF{Thinnable} so that \semfun{} may push
the environment under binders.
We call this constraint \ARF{th\textasciicircum{}𝓥},
using a caret to generate a mnemonic name: \ARF{th} refers to \emph{th}innable
and \ARF{𝓥} clarifies the family which is proven to be thinnable\footnote{
We use this convention consistently throughout the paper, using names
such as \AF{vl\textasciicircum{}Tm} for the proof that terms are
\AR{VarLike}}.

\begin{agdasnippet}
\addtolength{\leftskip}{\parindent}
  \ExecuteMetaData[StateOfTheArt/ACMM.tex]{thV}
\end{agdasnippet}
This constraint allows us to define \AF{extend}, the generalisation of
the two auxiliary definitions we used when defining \AF{ren} and
\AF{sub} at the start of Section~\ref{section:primer-program}, in
terms of the building blocks introduced in
Section~\ref{sec:genenvironment}.  It takes a context extension from
\AB{Δ} to \AB{Θ} in the form of a thinning, an existing evaluation
environment mapping \AB{Γ} variables to \AB{Δ} values and a value
living in the extended context \AB{Θ} and returns an evaluation
environment mapping ({\AB{σ} \AIC{∷} \AB{Γ}}) variables to \AB{Θ}
values.
% When defining a record in Agda, we are allowed to interleave field
% declarations and auxiliary definitions that may depend on the so-far already
% declared fields.

\begin{agdasnippet}
\addtolength{\leftskip}{\parindent}
\ExecuteMetaData[StateOfTheArt/ACMM.tex]{extend}
\end{agdasnippet}
Second, the set of computations needs to be closed under various
combinators which are the semantical counterparts of the language's
constructors.
For instance in the variable case we obtain a value from the evaluation
environment but we need to return a computation. This means that values
should embed into computations.

\begin{agdasnippet}
\addtolength{\leftskip}{\parindent}
\ExecuteMetaData[StateOfTheArt/ACMM.tex]{var}
\end{agdasnippet}
The semantical counterpart of application is an operation that takes a
representation of a function and a representation of an argument and
produces a representation of the result.

\begin{agdasnippet}
\addtolength{\leftskip}{\parindent}
\ExecuteMetaData[StateOfTheArt/ACMM.tex]{app}
\end{agdasnippet}
The interpretation of the λ-abstraction is of particular interest:
it is a variant on the Kripke function space one can find in normalisation
by evaluation~\cite{berger1991inverse,berger1993program,CoqDybSK,coquand2002formalised}.
In all possible thinnings of the scope at hand, it promises
to deliver a computation whenever it is provided with a value for its newly
bound variable. This is concisely expressed by the constraint's type:

\begin{agdasnippet}
\addtolength{\leftskip}{\parindent}
\ExecuteMetaData[StateOfTheArt/ACMM.tex]{lam}
\end{agdasnippet}

%\begin{figure}[h]
%\ExecuteMetaData[StateOfTheArt/ACMM.tex]{rsem}
%\caption{Semantics for \AD{Lam}}\label{figure:lamsem}
%\end{figure}

Agda allows us to package the definition of the generic traversal function
\semfun{} together with the fields of the record \semrec{}. This causes the
definition to be specialised and brought into scope for any instance of
\semrec{} the user will define.
We thus realise the promise made earlier, namely that any given
{\semrec{} \AB{𝓥} \AB{𝓒}} induces
a function which, given a value in \AB{𝓥} for each variable in scope,
transforms a  \AD{Lam} term into a computation \AB{𝓒}. This function is the proof of the Fundamental Lemma of Semantics for \AD{Lam}, relative to a given \semrec{} \AB{𝓥} \AB{𝓒}:

\begin{agdasnippet}
  \addtolength{\leftskip}{\parindent}
  \ExecuteMetaData[StateOfTheArt/ACMM.tex]{sem}
\end{agdasnippet}

% \begin{figure}[h]
% \caption{Fundamental Lemma of Semantics for \AD{Lam}, relative to a given \semrec{} \AB{𝓥} \AB{𝓒}}\label{figure:fdmlamsem}
% \end{figure}

\subsection{Instances of \texorpdfstring{\AR{Semantics}}{Semantics}}

Recall that each \AR{Semantics} is parametrised by two families: \AB{𝓥}
and \AB{𝓒}. During the evaluation of a term, variables are replaced by
values of type \AB{𝓥} and the overall result is a computation of type \AB{𝓒}.
Coming back to renaming and substitution:

\begin{minipage}{0.95\textwidth}
  \centering
  \begin{minipage}{0.6\textwidth}
    \ExecuteMetaData[StateOfTheArt/ACMM.tex]{semrenfun}
    \ExecuteMetaData[StateOfTheArt/ACMM.tex]{semsubfun}
  \end{minipage}
\end{minipage}

we see that they both fit in the
\semrec{} framework:

\begin{minipage}{0.95\textwidth}
  \begin{minipage}{0.47\textwidth}
    \ExecuteMetaData[StateOfTheArt/ACMM.tex]{semren}
  \end{minipage}\hfill
  \begin{minipage}{0.53\textwidth}
    \ExecuteMetaData[StateOfTheArt/ACMM.tex]{semsub}
  \end{minipage}
\end{minipage}

The family \AB{𝓥} of values is respectively the family
of variables for renaming, and the family of λ-terms for substitution.
In both cases \AB{𝓒} is the family of λ-terms because the result of the
operation will be a term.
We notice that the definition of substitution depends on
the definition of renaming: to be able to push terms under a binder, we need to
have already proven that they are thinnable.
In both cases we use \AF{extend} defined in Section~\ref{sec:genenvironment} as the definition of the
thinning which embeds \AB{Γ} into {(\AB{σ} \AIC{∷} \AB{Γ})}.

\label{section:printing}
We also include the definition of a basic printer relying on a name
supply to highlight the fact that computations can very well be
effectful. The ability to generate fresh names is given to us by a
monad that here we decide to call \AF{Fresh}. Concretely, \AF{Fresh} is implemented as an instance of the State monad where
the state is a stream of distinct strings:

\begin{agdasnippet}
  \ExecuteMetaData[StateOfTheArt/ACMM.tex]{monad}
\end{agdasnippet}

The \AF{Printing} semantics is defined by using \AF{Name}s (i.e. \AD{String}s)
as values and \AF{Printer}s (i.e. monadic actions in \AF{Fresh} returning a \AD{String})
as computations. We use a \AR{Wrap}per with a type and a context as phantom types
in order to help Agda's inference propagate the appropriate constraints. We define
a function \AF{fresh} that fetches a name from the name supply and makes sure it is
not available anymore.

\begin{agdasnippet}
  \ExecuteMetaData[StateOfTheArt/ACMM.tex]{valprint}
\end{agdasnippet}

\noindent
\begin{minipage}{0.95\textwidth}
\begin{minipage}{0.45\textwidth}
  \ExecuteMetaData[StateOfTheArt/ACMM.tex]{name}
  \ExecuteMetaData[StateOfTheArt/ACMM.tex]{printer}
\end{minipage}
\begin{minipage}{0.5\textwidth}
  \ExecuteMetaData[StateOfTheArt/ACMM.tex]{freshprint}
\end{minipage}
%\caption{Wrapper and fresh name generation}\label{fig:fresh}
\end{minipage}

The wrapper \AR{Wrap} does not depend on the scope \AB{Γ} so it is
automatically a thinnable functor, that is to say that we have the (used
but not shown here) definitions \AF{map\textasciicircum{}Wrap} witnessing
the functoriality of \AR{Wrap} and \AF{th\textasciicircum{}Wrap} witnessing
its thinnability. We jump straight
to the definition of the printer.

To print a variable, we are handed the \AR{Name} associated to it by the
environment and \AF{return} it immediately.

\begin{agdasnippet}
\ExecuteMetaData[StateOfTheArt/ACMM.tex]{printvar}
\end{agdasnippet}

To print an application, we produce a string representation, \AB{f}, of the term in
function position, then one, \AB{t}, of its argument and combine them by putting the
argument between parentheses.

\begin{agdasnippet}
\ExecuteMetaData[StateOfTheArt/ACMM.tex]{printapp}
\end{agdasnippet}

To print a λ-abstraction, we start by generating a fresh name, \AB{x}, for the
newly bound variable, use that name to generate a string \AB{b} representing the
body of the function to which we prepend a ``λ'' binding the name \AB{x}.

\begin{agdasnippet}
\ExecuteMetaData[StateOfTheArt/ACMM.tex]{printlam}
\end{agdasnippet}

Putting all of these pieces together, we get the \AF{Printing} semantics:

\begin{agdasnippet}
\ExecuteMetaData[StateOfTheArt/ACMM.tex]{semprint}
%\caption{Printing as an instance of \semrec{}}\label{fig:printing}
\end{agdasnippet}

We show how one can use this newly defined semantics to implement \AF{print},
a printer for closed terms assuming that we have already defined \AF{names},
a stream of distinct strings used as our name supply. We show the result of
running \AF{print} on the term \AF{apply}.

\begin{agdasnippet}
  \ExecuteMetaData[StateOfTheArt/ACMM.tex]{print}
  \ExecuteMetaData[StateOfTheArt/ACMM.tex]{applyprint}
\end{agdasnippet}

% \noindent
% \begin{minipage}[t]{0.5\textwidth}
% \begin{agdasnippet}
% \end{agdasnippet}
% \end{minipage}
% \quad
% \begin{minipage}[t]{0.4\textwidth}
% \begin{agdasnippet}
% \end{agdasnippet}
% \end{minipage}

Both printing and renaming highlight the importance of distinguishing
values and computations: the type of values in their respective
environments is distinct from their type of computations.

All of these examples are already described at length by ACMM~\citeyear{allais2017type}
so we will not spend any
more time on them. In ACMM we have also obtained the simulation and fusion
theorems demonstrating that these traversals are well behaved as
corollaries of more general results expressed in terms of \semfun{}.
We will come back to this in Section~\ref{section:simulation}.

One important observation to make is the tight connection between the constraints
described in \semrec{} and the definition of \AD{Lam}: the semantical counterparts
of the \AD{Lam} constructors are obtained by replacing the recursive occurrences of
the inductive family with either a computation or a Kripke function space depending
on whether an extra variable was bound. This suggests that it ought to be possible
to compute the definition of \semrec{} from the syntax description. Before doing this
in Section~\ref{section:universe}, we need to look at a generic descriptions of
data types.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% DATATYPES

\section{A primer on universes of data types}\label{section:data}

Chapman, Dagand, McBride and Morris (CDMM)~\citeyear{Chapman:2010:GAL:1863543.1863547}
defined a universe of data types inspired by Dybjer and Setzer's
finite axiomatisation of inductive-recursive definitions~\citeyear{Dybjer1999}
and Benke, Dybjer and Jansson's universes for generic programs and proofs~\citeyear{benke-ugpp}.
This explicit definition of \emph{codes} for data types empowers the
user to write generic programs tackling \emph{all} of the data types
one can obtain this way. In this section we recall the main aspects
of this construction we are interested in to build up our generic
representation of syntaxes with binding.

The first component of the definition of CDMM's universe (defined below) is an inductive type of
\AD{Desc}riptions of strictly positive functors from $\Set{}^J$ to $\Set{}^I$.
These functors correspond to \AB{I}-indexed containers of \AB{J}-indexed
payloads. Keeping these index types distinct prevents mistaking one for the
other when constructing the interpretation of descriptions. Later of course
we can use these containers as the nodes of recursive datastructures by
interpreting some payloads sorts as requests for
subnodes~\cite{DBLP:journals/jfp/AltenkirchGHMM15}.

The inductive type of descriptions has three constructors:
\AIC{`σ} to store data (the rest of
the description can depend upon this stored value), \AIC{`X} to attach a
recursive substructure indexed by $J$ and \AIC{`$\blacksquare$} to stop
with a particular index value.

The recursive function \AF{⟦\_⟧} makes the interpretation of the
descriptions formal. Interpretation of descriptions give rise
right-nested tuples terminated by equality constraints.

\noindent
\begin{minipage}{\textwidth}
  \begin{minipage}{0.52\textwidth}
    \noindent
    \ExecuteMetaData[StateOfTheArt/CDMM.tex]{desc}
  \end{minipage}
  \begin{minipage}{0.47\textwidth}
    \ExecuteMetaData[StateOfTheArt/CDMM.tex]{interp}
  \end{minipage}
\end{minipage}

These constructors give the programmer the ability to build up the data
types they are used to. For instance, the functor corresponding
to lists of elements in $A$ stores a \AD{Bool}ean which stands for whether
the current node is the empty list or not. Depending on its value, the
rest of the description is either the ``stop'' token or a pair of an element
in $A$ and a recursive substructure, that is, the tail of the list. The \AD{List} type
being unindexed, and we represent the lack of an index with the unit type \AD{$\top$}
whose unique inhabitant is \AIC{tt}.

\begin{agdasnippet}
\ExecuteMetaData[StateOfTheArt/CDMM.tex]{listD}
\end{agdasnippet}

Indices can be used to enforce invariants. For example, the type {\AD{Vec} \AB{A} \AB{n}}
of length-indexed lists. It has the same structure as the definition of \AF{listD}.
We start with a \AF{Bool}ean distinguishing the two constructors: either
the empty list (in which case the branch's index is enforced to be $0$) or a
non-empty one in which case we store a natural number \AB{n}, the head of type
\AB{A} and a tail of size \AB{n} (and the branch's index is enforced to be
\AIC{suc} \AB{n}).

\begin{agdasnippet}
\ExecuteMetaData[StateOfTheArt/CDMM.tex]{vecD}
\end{agdasnippet}

The pay-off for encoding our data types as descriptions is that we can define
generic programs for whole classes of data types. The decoding function \AF{⟦\_⟧}
acted on the objects of $\Set{}^J$, and we will now define the function \AF{fmap} by
recursion over a code \AB{d}. It describes the action of the functor corresponding
to \AB{d} over morphisms in $\Set{}^J$. This is the first example of generic
programming over all the functors one can obtain as the meaning of a description.

\begin{agdasnippet}
\ExecuteMetaData[StateOfTheArt/CDMM.tex]{fmap}
\end{agdasnippet}

All the functors obtained as meanings of \AD{Desc}riptions are strictly
positive. So we can build the least fixpoint of the ones that are endofunctors
(i.e. the ones for which $I$ equals $J$). This fixpoint is called \AD{μ}
and its iterator is given by the definition of \AF{fold} \AB{d}%%%
\footnote{The \AD{Size}~\cite{DBLP:journals/corr/abs-1012-4896} index added
to the inductive definition of \AD{μ} plays a crucial role in getting the
termination checker to see that \AF{fold} is a total function.
% Sized types are outside the scope of this paper; describing them in
% detail would be a distraction.
}
.

\begin{agdasnippet}
\ExecuteMetaData[StateOfTheArt/CDMM.tex]{mu}
\ExecuteMetaData[StateOfTheArt/CDMM.tex]{fold}
\end{agdasnippet}

This least fixpoint allows us to recover the data types we would
otherwise declare recursively and generatively. Pattern synonyms let us hide away the
encoding: users can use them to pattern-match on lists and Agda
conveniently resugars them when displaying a goal. Finally, we can get
our hands on the types' eliminators by instantiating the generic
\AF{fold}:

\noindent
\begin{minipage}{0.95\textwidth}
\begin{minipage}[t]{0.48\textwidth}
  \ExecuteMetaData[StateOfTheArt/CDMM.tex]{list}
  \ExecuteMetaData[StateOfTheArt/CDMM.tex]{nilcons}
\end{minipage}
\begin{minipage}[t]{0.50\textwidth}
  \ExecuteMetaData[StateOfTheArt/CDMM.tex]{foldr}
\end{minipage}
\end{minipage}

The CDMM approach, therefore, allows us to generically define iteration principles
for all data types that can be described. These are exactly the features we desire
for a universe of data types with binding, so in the next section we will see how
to extend CDMM's approach to include binding.

The functor underlying any well scoped and sorted syntax can be coded as some
{\AD{Desc} (\AB{I} \AR{×} \AD{List} \AB{I}) (\AB{I} \AR{×} \AD{List} \AB{I})},
 with the
free monad construction from CDMM uniformly adding the variable case. While a
good start, \AD{Desc} treats its index types as unstructured, so this construction
is blind to what makes the {\AD{List} \AB{I}} index a \emph{scope}.
The resulting
``bind'' operator demands a function which maps variables in \emph{any} sort and
scope to terms in the \emph{same} sort and scope. However, the behaviour we need
is to preserve sort while mapping between specific source and target scopes which
may differ. We need to account for the fact that scopes change only by extension,
and hence that our specifically scoped operations can be pushed under binders by
weakening.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% UNIVERSE OF SYNTAXES


\section{A universe of scope-safe and well sorted syntaxes}\label{section:universe}

Our universe of scope-safe and well sorted syntaxes follows the same principle
as CDMM's universe of data types, except that we are not building endofunctors on
$\Set{}^I$ any more but rather on {\AB{I} \AF{─Scoped}}. We now think of the
index type \AB{I} as the sorts
used to distinguish terms in our embedded language. The \AIC{`$\sigma$} and
\AIC{`∎} constructors are as in the CDMM \AD{Desc} type and are used to
represent data and index constraints respectively.
%%%
What distinguishes this new universe \AD{Desc} from that of Section~\ref{section:data}
is that the
%%%     The
\AIC{`X} constructor
is now augmented with an additional {\AD{List} \AB{I}} argument that describes
the new binders that are brought into scope at this recursive position. This
list of the sorts of the newly bound variables will play a crucial role when
defining the description's semantics as a binding structure below. % in
% Figures~\ref{figure:syntaxmeaning}, \ref{figure:debruijnscope} and \ref{figure:freemonad}.

\begin{agdasnippet}
\ExecuteMetaData[Generic/Syntax.tex]{desc}
\end{agdasnippet}

The meaning function \AF{⟦\_⟧} we associate to a description follows closely
its CDMM equivalent. It only departs from it in the \AIC{`X} case and the fact
it is not an endofunctor on \AB{I} \AF{─Scoped}; it is more general than that.
The function takes an \AB{X} of type {\AD{List} \AB{I} $\rightarrow$ \AB{I} \AD{─Scoped}}
to interpret {\AIC{`X} \AB{Δ} \AB{j}} (i.e. substructures of sort \AB{j} with
newly bound variables in \AB{Δ}) in an ambient scope \AB{Γ} as {\AB{X} \AB{Δ} \AB{j} \AB{Γ}}.

\begin{agdasnippet}
\ExecuteMetaData[Generic/Syntax.tex]{interp}
\end{agdasnippet}

The astute reader may have noticed that \AF{⟦\_⟧} is uniform in $X$ and $\Gamma$; however
refactoring \AF{⟦\_⟧} to use the partially applied $X\,\_\,\_\,\Gamma$ following
this observation would lead to a definition harder to use with the
combinators for indexed sets described in Section \ref{section:mech-reus}
which make our types much more readable.

If we pre-compose the meaning function \AF{⟦\_⟧} with a notion of `de Bruijn scopes'
(denoted \AF{Scope} here) which turns any \AB{I} \AF{─Scoped} family into a function
of type \AD{List} \AB{I} \AS{→} \AB{I} \AF{─Scoped} by appending the two
\AD{List} indices, we recover a meaning function producing an endofunctor on
\AB{I} \AF{─Scoped}. So far we have only shown the action of the functor on objects;
its action on morphisms is given by a function \AF{fmap} defined by induction over
the description just as in Section~\ref{section:data}.

\begin{agdasnippet}
\ExecuteMetaData[Generic/Syntax.tex]{scope}
\end{agdasnippet}

The endofunctors thus defined are strictly positive and we can take their fixpoints.
As we want to define the terms of a language with variables, instead of
considering the initial algebra, this time we opt for the free relative
monad~\cite{JFR4389} (with respect to the functor \AF{Var}): the \AIC{`var}
constructor corresponds to return, and we will define bind (also known as
the parallel substitution \AF{sub}) in the next section.

% We have once more a \AD{Size} index to get all the benefits of type
% based termination checking.

\begin{agdasnippet}
\ExecuteMetaData[Generic/Syntax.tex]{mu}
\end{agdasnippet}

Coming back to our original examples, we now have the ability to give
codes for the well scoped untyped λ-calculus and, just as well,
the intrinsically typed STLC. We add a third
example to showcase the whole spectrum of syntaxes: a well scoped and
well sorted but not well typed bidirectional language. In all examples,
the variable case will be added by the free monad construction so we only
have to describe the other constructors.


\paragraph*{Un(i)typed λ-calculus (UTLC)} For the untyped case, the lack of
type translates to picking the unit type (\AR{⊤}) as our notion of sort.
We have two possible
constructors: application where we have two substructures which do not bind
any extra argument and λ-abstraction which has exactly one substructure
with precisely one extra bound variable. A single \AD{Bool}ean is enough to
distinguish the two constructors.

\begin{agdasnippet}
  \ExecuteMetaData[Generic/Syntax/UTLC.tex]{ULC}
\end{agdasnippet}

\paragraph*{Bidirectional STLC}\label{par:bidirectional} Our second example is a
bidirectional~\cite{pierce2000local} language hence the introduction of a
notion of \AD{Mode}: each term is either part of the \AIC{Infer} or
\AIC{Check} fraction of the language. This language has four constructors
which we list in the ad hoc \AD{`Bidi} type of constructor tags, its
decoding \AD{Bidi} is defined by a pattern-matching λ-expression in Agda.
Application and λ-abstraction behave as expected, with the important
observation that λ-abstraction binds an \AIC{Infer}rable term. The two
remaining constructors correspond to changes of direction: one can freely
\AIC{Emb}bed inferrable terms as checkable ones whereas we require a type
annotation when forming a \AIC{Cut} (we reuse the notion of \AD{Type} introduced
in the STLC example at the end of Section~\ref{section:primer-term}). % Figure~\ref{fig:intrinsic-stlc}).

\noindent
\begin{minipage}{0.95\textwidth}
\begin{minipage}[t]{0.3\textwidth}
  \ExecuteMetaData[Generic/Syntax/Bidirectional.tex]{tagmode}
\end{minipage}\quad
\begin{minipage}[t]{0.65\textwidth}
  \ExecuteMetaData[Generic/Syntax/Bidirectional.tex]{desc}
\end{minipage}
\end{minipage}

\paragraph*{Intrinsically typed STLC}\label{par:intrinsicSTLC}
In the typed case (for the same notion of \AD{Type}), we are back to two
constructors: the terms are fully annotated and therefore it is not necessary
to distinguish between \AD{Mode}s anymore. We need our tags to carry extra
information about the types involved so we use once more an ad hoc data type
\AD{`STLC}, and define its decoding \AD{STLC} by a pattern-matching λ-expression.

\noindent
\begin{minipage}{0.95\textwidth}
\begin{minipage}[t]{0.48\textwidth}
  \ExecuteMetaData[Generic/Syntax/STLC.tex]{tag}
\end{minipage}
\begin{minipage}[t]{0.515\textwidth}
  \ExecuteMetaData[Generic/Syntax/STLC.tex]{desc}
\end{minipage}
\end{minipage}

For convenience we use Agda's pattern synonyms corresponding to the
original constructors in Section \ref{section:mech-reus}. These
synonyms can be used when pattern-matching on a term and Agda resugars
them when displaying a goal. This means that the end user can
seamlessly work with encoded terms without dealing with the gnarly
details of the encoding.  These pattern definitions can omit some
arguments using ``\AS{\_}'', in which case they will be filled in
by unification just like any other implicit argument: there is no
extra cost to using an encoding!  The only downside is that the
language currently does not allow the user to specify type annotations
for pattern synonyms. We only include examples of pattern synonyms
for the two extreme examples, the definition for \AF{Bidi} are similar.

\noindent
\begin{minipage}{0.99\textwidth}
\begin{minipage}{0.47\textwidth}
  \ExecuteMetaData[Generic/Syntax/UTLC.tex]{LCpat}
\end{minipage}
\begin{minipage}{0.52\textwidth}
  \ExecuteMetaData[Generic/Syntax/STLC.tex]{patST}
\end{minipage}
\end{minipage}

As a usage example of these pattern synonyms, we define the identity
function in all three languages, using the
same caret-based naming convention we introduced earlier. The code
is virtually the same except for \AF{Bidi} which explicitly records
the change of direction from \AIC{Check} to \AIC{Infer}.

\noindent
\begin{minipage}{\textwidth}
\begin{minipage}{0.28\textwidth}
  \ExecuteMetaData[Generic/Syntax/UTLC.tex]{LCid}
\end{minipage}
\begin{minipage}{0.34\textwidth}
  \ExecuteMetaData[Generic/Syntax/Bidirectional.tex]{BDid}
\end{minipage}
\begin{minipage}{0.36\textwidth}
  \ExecuteMetaData[Generic/Syntax/STLC.tex]{STid}
\end{minipage}
\end{minipage}
% \begin{minipage}{\textwidth}
% \end{minipage}


\paragraph*{A sum combinator for syntaxes}\label{desccomb}

The definition of \AF{UTLC} is the third time (the first and second
times being the definition of \AF{listD} and \AF{vecD} in
Section~\ref{section:data}) that we use a \AF{Bool} to distinguish
between two constructors. We can abstract this common pattern as a combinator \AF{\_`+\_} together
with an appropriate eliminator \AF{case} which, given two methods,
picks the one corresponding to the chosen branch.

\noindent
\begin{minipage}{0.95\textwidth}
\begin{minipage}[t]{0.42\textwidth}
  \ExecuteMetaData[Generic/Syntax.tex]{descsum}
\end{minipage}
\begin{minipage}[t]{0.57\textwidth}
  \ExecuteMetaData[Generic/Syntax.tex]{case}
\end{minipage}
%\caption{Descriptions are closed under Sum}\label{figure:descsum}
\end{minipage}

% Closure under product does not hold in general. Indeed, the
% equality constraints introduced by the two end tokens of two
% descriptions may be incompatible. So far, a limited form of
% closure (closure under finite product of recursive positions)
% has been sufficient for all of our use cases. As with coproducts,
% the appropriate eliminator \AF{unXs} takes a value in the encoding
% and extracts its constituents ({\AF{All} \AB{P} \AB{xs}} is defined
% in Agda's standard library and makes sure that the predicate \AB{P}
% holds true of all the elements in the list \AB{xs}).

% \begin{figure}[h]
% \begin{minipage}{0.4\textwidth}
%   \ExecuteMetaData[Generic/Syntax.tex]{paircomb}
% \end{minipage}\hfill
% \begin{minipage}{0.5\textwidth}
%   \ExecuteMetaData[Generic/Syntax.tex]{pairunpair}
% \end{minipage}
% \caption{Descriptions are closed under Finite Products of Recursive Positions}
% \end{figure}

A concrete use case for this combinator will be given in
Section~\ref{section:letbinding}
where we explain how to seamlessly enrich an existing syntax with let bindings
and how to use the \semrec{} framework to elaborate them away.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% GENERIC SEMANTICS


\section{Generic scope-safe and well sorted programs for syntaxes}\label{section:semantics}

Based on the \semrec{} type we defined for the specific example of the
simply typed λ-calculus in Section~\ref{section:primer-program},
we can define a generic notion of
semantics for all syntax descriptions. It is once more parametrised
by two \AB{I}\AF{─Scoped} families \AB{𝓥} and \AB{𝓒} corresponding,
respectively, to \emph{values} associated to bound variables and
\emph{computations} delivered by evaluating terms. These two families
have to abide by three constraints:
\begin{itemize}
\item{\ARF{th\textasciicircum{}𝓥}} Values should be thinnable so that we can push the
      evaluation environment under binders;
\item{\ARF{var}} Values should embed into computations for us to be able
      to return the value associated to a variable as the
      result of its evaluation;
\item{\ARF{alg}} We should have an algebra turning
      a term whose substructures have been replaced with
      computations (possibly under some binders, represented semantically
      by the \AF{Kripke} type-valued function defined below) into computations
\end{itemize}

\begin{agdasnippet}
\ExecuteMetaData[Generic/Semantics.tex]{semantics}
\end{agdasnippet}

Here we crucially use the fact that the meaning of a description is
defined in terms of a function interpreting substructures which has
the type \AF{List} \AB{I} \AS{→} \AB{I}\AF{─Scoped}, that is, that gets access
to the current scope but also the exact list of the sorts of the newly bound variables.
We define a function \AF{Kripke} by case analysis on the number of newly bound
variables. It is essentially a subcomputation waiting for a value associated to
each one of the fresh variables.
\begin{itemize}
\item If it is $0$ we expect the substructure to be a computation corresponding
    to the result of the evaluation function's recursive call;
  \item But if there are newly bound variables then we expect to have a function
    space. In any context extension, it will take an environment of values for
    the newly bound variables and produce a computation corresponding to the
    evaluation of the body of the binder.
\end{itemize}

\begin{agdasnippet}
\ExecuteMetaData[Data/Environment.tex]{kripke}
\end{agdasnippet}

It is once more the case that the abstract notion of Semantics comes
with a fundamental lemma: all \AB{I} \AF{─Scoped} families \AB{𝓥} and
\AB{𝓒} satisfying the three criteria we have put forward give rise
to an evaluation function. We introduce a notion of computation
\AF{\_─Comp} analogous to that of environments: instead of associating
values to variables, it associates computations to terms.

\begin{agdasnippet}
  \ExecuteMetaData[Generic/Semantics.tex]{comp}
\end{agdasnippet}

\subsection{Fundamental lemma of semantics}\label{sec:fundamentallemma}

We can now define the type of the fundamental lemma (called \semfun{}) which
takes a semantics and returns a function from environments to computations.
It is defined mutually with a
function \AF{body} turning syntactic binders into semantic binders: to
each de Bruijn \AF{Scope} (i.e. a substructure in a potentially extended
context) it associates a \AF{Kripke} (i.e. a subcomputation expecting a
value for each newly bound variable).

\begin{agdasnippet}
  \ExecuteMetaData[Generic/Semantics.tex]{semtype}
\end{agdasnippet}

The \semfun{} proof is straightforward now that we have clearly
identified the problem structure and the constraints we need to enforce.
If the term considered is a variable, we look up the associated value in
the evaluation environment and turn it into a computation using \ARF{var}.
If it is a non-variable constructor then we call \AF{fmap} to evaluate the
substructures using \AF{body} and then call the \ARF{alg}ebra to combine
these results.

\begin{agdasnippet}
  \ExecuteMetaData[Generic/Semantics.tex]{semproof}
\end{agdasnippet}

The auxiliary lemma \AF{body} distinguishes two cases. If no new
variable has been bound in the recursive substructure, it is
a matter of calling \semfun{} recursively. Otherwise we are provided
with a \AF{Thinning}, some additional values and evaluate the
substructure in the thinned and extended evaluation environment
(thanks to a auxiliary function \AF{\_>>\_} which given two environments
{(\AB{Γ} \AR{─Env}) \AB{𝓥} \AB{Θ}} and {(\AB{Δ} \AR{─Env}) \AB{𝓥} \AB{Θ}}
produces an environment {((\AB{Γ} \AF{++} \AB{Δ}) \AR{─Env}) \AB{𝓥} \AB{Θ})}.

\begin{agdasnippet}
  \ExecuteMetaData[Generic/Semantics.tex]{bodyproof}
\end{agdasnippet}

Given that \AF{fmap} introduces one level of indirection between the
recursive calls and the subterms they are acting upon, the fact
that our terms are indexed by a \AF{Size} is once more crucial in
getting the termination checker to see that our proof is indeed
well founded.

We immediately introduce \AF{closed}, a corollary of the fundamental lemma of
semantics for the special cases of closed terms.

\begin{agdasnippet}
  \ExecuteMetaData[Generic/Semantics.tex]{closed}
\end{agdasnippet}

Given a \AR{Semantics} with value type \AB{𝓥} and computation type \AB{𝓒},
we can evaluate a closed term of type \AB{σ} and obtain a computation of
type {(\AB{𝓒} \AB{σ} \AIC{[]})} by kickstarting the evaluation with an
empty environment.


\subsection{Our first generic programs: renaming and substitution}%
\label{section:renandsub}

Similarly to ACMM~\citeyear{allais2017type} renaming can be defined generically
for all syntax descriptions as a semantics with \AF{Var} as values and \AD{Tm} as
computations. The first two constraints on \AF{Var} described earlier are trivially
satisfied. Observing that renaming strictly respects the structure of the term it
goes through, it makes sense for the algebra to be implemented using \AF{fmap}.
When dealing with the body of a binder, we ``reify'' the \AF{Kripke} function by
evaluating it in an extended context and feeding it placeholder values corresponding to
the extra variables introduced by that context. This is reminiscent both of what we
did in Section~\ref{section:primer-program} and the definition of reification in
the setting of normalisation by evaluation
(see e.g. Catarina Coquand's formal development~\citeyear{coquand2002formalised}).

Substitution is defined in a similar manner with \AD{Tm} as both
values and computations. Of the two constraints applying to terms as
values, the first one corresponds to renaming and the second
one is trivial. The algebra is once more defined by using \AF{fmap}
and reifying the bodies of binders.

\noindent
\begin{minipage}{\textwidth}
\begin{minipage}{0.5\textwidth}
  \ExecuteMetaData[Generic/Semantics/Syntactic.tex]{renaming}
  \ExecuteMetaData[Generic/Semantics/Syntactic.tex]{ren}
\end{minipage}\hfill
\begin{minipage}{0.5\textwidth}
  \ExecuteMetaData[Generic/Semantics/Syntactic.tex]{substitution}
  \ExecuteMetaData[Generic/Semantics/Syntactic.tex]{sub}
\end{minipage}
\end{minipage}

The reification process mentioned in the definition of renaming and
substitution can be implemented generically for \semrec{} families
which have \AR{VarLike} values, that is, values which are \AF{Thinnable} and
such that we can craft placeholder values in non-empty contexts. It is
almost immediate that both \AD{Var} and \AD{Tm} are \AR{VarLike} (with
proofs \AF{vl\textasciicircum{}Var} and \AF{vl\textasciicircum{}Tm},
respectively).

\begin{agdasnippet}
  \ExecuteMetaData[Data/Var/Varlike.tex]{varlike}
\end{agdasnippet}

\label{sec:varlike:base}
Given a proof that \AB{𝓥} is \AR{VarLike}, we can manufacture
  several useful environments of values \AB{𝓥}. We provide users with
  \AF{base} of type {(\AB{Γ} \AR{─Env}) \AB{𝓥} \AB{Γ}},
  \AF{fresh\textsuperscript{r}} of type {(\AB{Γ} \AR{─Env}) \AB{𝓥} (\AB{Δ} \AF{++} \AB{Γ})}
  and \AF{fresh\textsuperscript{l}} of type {(\AB{Γ} \AR{─Env}) \AB{𝓥} (\AB{Γ} \AF{++} \AB{Δ})}
  by combining the use of placeholder values and thinnings.
  In the \AD{Var} case these very general definitions respectively specialise
  to the identity renaming for a context \AB{Γ} and the injection of \AB{Γ}
  fresh variables to the right or the left of an ambient context \AB{Δ}.
  %%%
  Similarly, in the \AD{Tm} case, we can show \AF{base} \AF{vl\textasciicircum{}Tm}
  extensionally equal to the identity environment \AF{id\textasciicircum{}Tm}
  given by {\ARF{lookup} \AF{id\textasciicircum{}Tm} = \AIC{`var}},
  which associates each variable to itself (seen as a term).
Using these definitions, we can then implement \AF{reify} as follows:

\begin{agdasnippet}
  \ExecuteMetaData[Data/Var/Varlike.tex]{reify}
\end{agdasnippet}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% OTHER GENERIC FUNCTIONS

\section{A catalogue of generic programs for syntax with binding}
\label{section:catalogue}

In this section we explore a large part of the spectrum of traversals a
compiler writer may need when implementing their own language.
In Section~\ref{section:genericprinting} we look at the production of
human-readable representations of internal syntax; in Section~\ref{section:genericscoping}
we write a generic scope checker thus bridging the gap between raw data
fresh out of a parser to well scoped syntax; we then demonstrate how to
write a type checker in Section~\ref{section:typechecking} and even an
elaboration function turning well scoped into well scoped and typed syntax
in Section~\ref{section:elaboration}. We then study type and scope respecting
transformations on internal syntax: desugaring in Section~\ref{section:letbinding}
and size preserving inlining in Section~\ref{section:inlining}. We conclude
with an unsafe but generic evaluator defined using normalisation by evaluation
in Section~\ref{section:nbyeval}.

\input{catalogue/printing.tex}
\input{catalogue/scopechecking.tex}
\input{catalogue/typechecking.tex}
\input{catalogue/elaborating.tex}
\input{catalogue/desugaring.tex}
\input{catalogue/inlining.tex}
\input{catalogue/normalising.tex}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% OTHER OPPORTUNITIES FOR GENERIC PROGRAMMING

\section{Other opportunities for generic programming}

Some generic programs of interest do not fit in the \AR{Semantics}
framework. They can still be implemented once and for all, and even
benefit from the \AR{Semantics}-based definitions.

We will first explore existing work on representing cyclic structures
using a syntax with binding: a binder is a tree node declaring a pointer
giving subtrees the ability to point back to it, thus forming a cycle.
Substitution will naturally play a central role in giving these finite
terms a semantics as their potentially infinite unfolding.

We will then see that many of the standard traversals produced by the
``deriving'' machinery familiar to Haskell programmers can be implemented
on syntaxes too, sometimes with more informative types.

\input{catalogue/unrolling.tex}
\input{catalogue/equality.tex}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% GENERIC PROOFS

\section{Building generic proofs about generic programs}

In ACMM~\citeyear{allais2017type} we have
already shown that, for the simply typed λ-calculus, introducing an abstract
notion of \AF{Semantics} not only reveals the shared structure of common
traversals, it also allows us to give abstract proof frameworks for
simulation or fusion lemmas. This idea naturally extends to our generic
presentation of semantics for all syntaxes.


\subsection{Relations and relation transformers}

In our exploration of generic proofs about the behaviour of various \AR{Semantics},
we are going to need to manipulate relations between distinct notions of values or
computations. In this section, we introduce the notion of relation we are going to
use as well as these two key relation transformers.

In Section~\ref{sec:genenvironment} we introduced a generic notion of well typed
and scoped environment as a function from variables to values. Its formal definition
is given as a record type. This record wrapper helps
Agda's type inference reconstruct the type family of values whenever it is passed an
environment.

For the same reason, we will use a record wrapper for the concrete implementation of
our notion of relation over (I \AF{─Scoped}) families. A \AR{Rel}ation between two
such families \AB{T} and \AB{U} is a function which to any \AB{σ} and \AB{Γ} associates
a relation between (\AB{T} \AB{σ} \AB{Γ}) and (\AB{U} \AB{σ} \AB{Γ}). Our first example
of such a relation is \AF{Eqᴿ} the equality relation between an (\AB{I}\AF{─Scoped})
family \AB{T} and itself.

\noindent
\begin{minipage}{\textwidth}
  \begin{minipage}[t]{0.65\textwidth}
    \ExecuteMetaData[Data/Relation.tex]{rel}
  \end{minipage}
  \begin{minipage}[t]{0.25\textwidth}
    \ExecuteMetaData[Data/Relation.tex]{eqR}
  \end{minipage}
\end{minipage}

Once we know what relations are, we are going to have to lift relations on values
and computations to relations on environments, \AF{Kripke} function spaces or
on \AB{d}-shaped terms whose subterms have been evaluated already.
This is what the rest of this section focuses on.

\paragraph*{Environment relator}
Provided a relation \AB{𝓥ᴿ} for notions of values \AB{𝓥ᴬ} and \AB{𝓥ᴮ}, by
pointwise lifting we can define a relation {(\AR{All} \AB{𝓥ᴿ} \AB{Γ})} on
\AB{Γ}-environments of values \AB{𝓥ᴬ} and \AB{𝓥ᴮ} respectively. We once more
use a record wrapper simply to facilitate Agda's job when reconstructing
implicit arguments.

\begin{agdasnippet}
  \ExecuteMetaData[Data/Relation.tex]{all}
\end{agdasnippet}

The first example of two environment being related is \AF{reflᴿ} that, to any
environment \AB{ρ} associates a trivial proof of the statement
{(\AR{All} \AF{Eqᴿ} \AB{Γ} \AB{ρ} \AB{ρ})}.
The combinators we introduced in Section~\ref{sec:genenvironment} to build environments
(\AF{ε}, \AF{\_∙\_}, etc.) have natural relational counterparts. We reuse the same
names for them, simply appending an \AF{ᴿ} suffix.

\paragraph*{Kripke relator}
We assume that we have two types of values \AB{𝓥ᴬ} and \AB{𝓥ᴮ}
as well as a relation \AB{𝓥ᴿ} for pairs of such values, and two types of computations
\AB{𝓒ᴬ} and \AB{𝓒ᴮ} whose notion of relatedness is given by \AB{𝓒ᴿ}. We can define
\AF{Kripkeᴿ} relating Kripke functions of type
{(\AF{Kripke} \AB{𝓥ᴬ} \AB{𝓒ᴬ})} and {(\AF{Kripke} \AB{𝓥ᴮ} \AB{𝓒ᴮ})}
respectively by stating that they send related inputs
to related outputs. We use the relation transformer \AF{All} defined in the previous
paragraph.

\begin{agdasnippet}
  \ExecuteMetaData[Data/Var/Varlike.tex]{kripkeR}
\end{agdasnippet}

\paragraph*{Desc relator}
The relator (\AF{⟦} \AB{d} \AF{⟧ᴿ}) is a relation transformer which characterises
structurally equal layers such that their substructures are themselves related
by the relation it is passed as an argument. It inherits a lot of its relational
arguments' properties: whenever \AB{R} is reflexive (respectively symmetric or
transitive) so is {(\AF{⟦} \AB{d} \AF{⟧ᴿ} \AB{R})}.\label{lem:zipstable}

It is defined by induction on the description and case analysis on the two
layers which are meant to be equal:
\begin{itemize}
  \item In the stop token case \AIC{`∎} \AB{i}, the two layers are considered to
    be trivially equal (i.e. the constraint generated is the unit type)
  \item When facing a recursive position {\AIC{`X} \AB{$\Delta$} \AB{j} \AB{d}}, we
    demand that the two substructures are related by {\AB{R} \AB{$\Delta$} \AB{j}}
    and that the rest of the layers are related by (\AF{⟦} \AB{d} \AF{⟧ᴿ} \AB{R})
  \item Two nodes of type {\AIC{`$\sigma$} \AB{A} \AB{d}} will
    be related if they both carry the same payload \AB{a} of type \AB{A} and if
    the rest of the layers are related by (\AF{⟦} \AB{d} \AB{a} \AF{⟧ᴿ} \AB{R})
\end{itemize}

\begin{agdasnippet}
  \ExecuteMetaData[Generic/Relator.tex]{ziptype}
\end{agdasnippet}

If we were to take a fixpoint of \AF{⟦\_⟧ᴿ}, we could obtain a structural
notion of equality for terms which we could prove equivalent to propositional
equality. Although interesting in its own right, this section will focus
on more advanced use cases.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% SIMULATION


\subsection{Simulation lemma}\label{section:simulation}

A constraint mentioning all three relation transformers appears naturally when
we want to say that a semantics can simulate another one. For instance, renaming
is simulated by substitution: we simply have to restrict ourselves to environments
mapping variables to terms which happen to be variables.
More generally, given a semantics \AB{𝓢ᴬ} with values \AB{𝓥ᴬ} and computations
\AB{𝓒ᴬ} and a semantics \AB{𝓢ᴮ} with values \AB{𝓥ᴮ} and computations \AB{𝓒ᴮ},
we want to establish the constraints under which these two semantics yield
related computations provided they were called with environments of related values.

These constraints are packaged in a record type called \AR{Simulation} and
parametrised over the semantics as well as the notion of relatedness used
for values (given by a relation \AB{𝓥ᴿ}) and computations
(given by a relation \AB{𝓒ᴿ}).

\begin{agdasnippet}
  \ExecuteMetaData[Generic/Simulation.tex]{recsim}
\end{agdasnippet}

The two first constraints are self-explanatory: the operations
\ARF{th\textasciicircum{}𝓥} and \ARF{var} defined by each semantics
should be compatible with the notions of relatedness used for values and computations.

\begin{agdasnippet}
\addtolength{\leftskip}{\parindent}
  \ExecuteMetaData[Generic/Simulation.tex]{thR}
% \end{agdasnippet}
% \begin{agdasnippet}
% \addtolength{\leftskip}{\parindent}
  \ExecuteMetaData[Generic/Simulation.tex]{varR}
\end{agdasnippet}

The third constraint is similarly simple: the algebras (\ARF{alg}) should take
related recursively evaluated subterms of respective types
\AF{⟦} \AB{d} \AF{⟧} (\AF{Kripke} \AB{𝓥ᴬ} \AB{𝓒ᴬ}) and
\AF{⟦} \AB{d} \AF{⟧} (\AF{Kripke} \AB{𝓥ᴮ} \AB{𝓒ᴮ}) to related computations.
The difficuly is in defining an appropriate notion of relatedness \AF{bodyᴿ}
for these recursively evaluated subterms.

\begin{agdasnippet}
\addtolength{\leftskip}{\parindent}
  \ExecuteMetaData[Generic/Simulation.tex]{algR}
\end{agdasnippet}

We can combine \AF{⟦\_⟧ᴿ} and \AF{Kripkeᴿ} to express the idea that two recursively
evaluated subterms are related whenever they have an equal shape (which means their
Kripke functions can be grouped in pairs) and that all the pairs of Kripke function
spaces take related inputs to related outputs.

\begin{agdasnippet}
\addtolength{\leftskip}{\parindent}
  \ExecuteMetaData[Generic/Simulation.tex]{bodyR}
\end{agdasnippet}

The fundamental lemma of simulations is a generic theorem showing that for
each pair of \semrec{} respecting the \AR{Simulation} constraint, we
get related computations given environments of related input values.
This theorem is once more mutually
proven with a statement about \AF{Scope}s,
and \AD{Size}s play a crucial role in ensuring that the function is indeed total.

\begin{agdasnippet}
  \addtolength{\leftskip}{\parindent}
  \ExecuteMetaData[Generic/Simulation.tex]{simbody}
\end{agdasnippet}

Instantiating this generic simulation lemma, we can for instance prove
that renaming is a special case of substitution, or that renaming and
substitution are extensional, that is, that given environments equal in
a pointwise manner they produce syntactically equal terms. Of course these
results are not new but having them generically over all syntaxes with
binding is convenient. We experienced this first hand when tackling the
POPLMark Reloaded challenge~\citeyear{poplmarkreloaded} where
\AF{rensub} was actually needed.

\begin{agdasnippet}
  \ExecuteMetaData[Generic/Simulation/Syntactic.tex]{rensubfun}
  \ExecuteMetaData[Generic/Simulation/Syntactic.tex]{rensub}
\end{agdasnippet}

When studying specific languages, new opportunities to deploy the
fundamental lemma of simulations arise. Our solution to the POPLMark
Reloaded challenge
%%%\citeyear{{abel_allais_hameer_pientka_momigliano_schäfer_stark_2019}
for instance describes the fact that
{(\AF{sub} \AB{$\rho$} \AB{t})}
reduces to {(\AF{sub} \AB{$\rho$'} \AB{t})} whenever for all \AB{v},
\AB{$\rho$}(\AB{v}) reduces to \AB{$\rho$'}(\AB{v}) as a \AR{Simulation}.
The main theorem (strong normalisation of STLC via a logical relation)
is itself an instance of (the unary version of) the simulation lemma.

The \AR{Simulation} proof framework is the simplest example of the abstract
proof frameworks introduced in ACMM~\citeyear{allais2017type}. We also
explain how a similar framework can be defined
for fusion lemmas and deploy it for the renaming-substitution interactions
but also their respective interactions with normalisation by evaluation.
Now that we are familiarised with the techniques at hand, we can tackle
this more complex example for all syntaxes definable in our framework.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% FUSION

\subsection{Fusion lemma}\label{section:fusion}

Results that can be reformulated as the ability to fuse two traversals
obtained as \semrec{} into one abound. When claiming that \AF{Tm} is
a Functor, we have to prove that two successive renamings can be fused into
a single renaming where the \AF{Thinning}s have been composed. Similarly,
demonstrating that \AF{Tm} is a relative Monad~\cite{JFR4389} implies proving
that two consecutive substitutions can be merged into a single one whose
environment is the first one, where the second one has been applied in a
pointwise manner. The \emph{Substitution Lemma} central
to most model constructions (see e.g.,~\cite{mitchell1991kripke}) states
that a syntactic substitution followed by the evaluation of the resulting term
into the model is equivalent to the evaluation of the original term with an
environment corresponding to the evaluated substitution.

A direct application of these results is our (to be published) entry
%%%\citeyear{{abel_allais_hameer_pientka_momigliano_schäfer_stark_2019}
to the
POPLMark Reloaded challenge~\citeyear{poplmarkreloaded}. Using a \AD{Desc}-based
representation of intrinsically well typed and well scoped terms we directly inherit
not only renaming and substitution but also all four fusion lemmas as corollaries
of our generic results. This allows us to remove the usual boilerplate
and go straight to the point.
As all of these statements have precisely the same structure, we can
once more devise a framework which will, provided that its constraints are
satisfied, prove a generic fusion lemma.

Fusion is more involved than simulation; we will once more step through
each one of the constraints individually, trying to give the reader an intuition
for why they are shaped the way they are.

\subsubsection{The fusion constraints}

The notion of fusion is defined for a triple of \AR{Semantics}; each \AB{𝓢ⁱ}
being defined for values in \AB{𝓥ⁱ} and computations in \AB{𝓒ⁱ}. The
fundamental lemma associated to such a set of constraints will state that
running \AB{𝓢ᴮ} after \AB{𝓢ᴬ} is equivalent to running \AB{𝓢ᴬᴮ} only.

The definition of fusion is parametrised by three relations: \AB{𝓔ᴿ} relates
triples of environments of values in {(\AB{Γ} \AR{─Env}) \AB{𝓥ᴬ} \AB{Δ}},
{(\AB{Δ} \AR{─Env}) \AB{𝓥ᴮ} \AB{Θ}} and {(\AB{Γ} \AR{─Env}) \AB{𝓥ᴬᴮ} \AB{Θ}}
respectively; \AB{𝓥ᴿ} relates pairs of values \AB{𝓥ᴮ} and \AB{𝓥ᴬᴮ};
and \AB{𝓒ᴿ}, our notion of equivalence for evaluation results, relates pairs
of computation in \AB{𝓒ᴮ} and \AB{𝓒ᴬᴮ}.

\begin{agdasnippet}
\ExecuteMetaData[Generic/Fusion.tex]{fusionrec}
\end{agdasnippet}
The first obstacle we face is the formal definition of ``running \AB{𝓢ᴮ}
after \AB{𝓢ᴬ}'': for this statement to make sense, the result of running
\AB{𝓢ᴬ} ought to be a term. Or rather, we ought to be able to extract a
term from a \AB{𝓒ᴬ}. Hence the first constraint: the existence of a \ARF{reifyᴬ}
function, which we supply as a field of the record \AR{Fusion}. When dealing with
syntactic semantics such as renaming or substitution
this function will be the identity. Nothing prevents proofs, such as the
idempotence of NbE, which use a bona fide reification function that extracts
terms from model values.

\begin{agdasnippet}
\addtolength{\leftskip}{\parindent}
\ExecuteMetaData[Generic/Fusion.tex]{reify}
\end{agdasnippet}
Then, we have to think about what happens when going under a binder: \AB{𝓢ᴬ}
will produce a \AF{Kripke} function space where a syntactic
value is required. Provided that \AB{𝓥ᴬ} is \AR{VarLike}, we can make use of \AF{reify}
to get a \AF{Scope} back. Hence the second constraint is:

\begin{agdasnippet}
\addtolength{\leftskip}{\parindent}
\ExecuteMetaData[Generic/Fusion.tex]{vlV}
\end{agdasnippet}
Still thinking about going under binders: if three evaluation environments
\AB{ρᴬ} in {(\AB{Γ} \AR{─Env}) \AB{𝓥ᴬ} \AB{Δ}}, \AB{ρᴮ} in
{(\AB{Δ} \AR{─Env}) \AB{𝓥ᴮ} \AB{Θ}}, and \AB{ρᴬᴮ} in {(\AB{Γ} \AR{─Env}) \AB{𝓥ᴬᴮ} \AB{Θ}}
are related by \AB{𝓔ᴿ} and we are given a thinning \AB{σ} from \AB{Θ} to \AB{Ω}
then \AB{ρᴬ}, the thinned \AB{ρᴮ} and the thinned \AB{ρᴬᴮ} should still be related.

\begin{agdasnippet}
\addtolength{\leftskip}{\parindent}
\ExecuteMetaData[Generic/Fusion.tex]{thV}
\end{agdasnippet}
Remembering that \AF{\_>>\_} is used in the definition of \AF{body} (Section~\ref{sec:fundamentallemma}) to
combine two disjoint environments {(\AB{Γ} \AR{─Env}) \AB{𝓥} \AB{Θ}} and
{(\AB{Δ} \AR{─Env}) \AB{𝓥} \AB{Θ}} into one of type
{((\AB{Γ} \AF{++} \AB{Δ}) \AR{─Env}) \AB{𝓥} \AB{Θ})}, we mechanically need a
constraint stating that \AF{\_>>\_} is compatible with \AB{𝓔ᴿ}. We demand
as an extra precondition that the values \AB{ρᴮ} and \AB{ρᴬᴮ} are extended
with are related according to \AB{𝓥ᴿ}. Lastly, for all the types to match up,
\AB{ρᴬ} has to be extended with placeholder variables which is possible because
we have already insisted on \AB{𝓥ᴬ} being \AR{VarLike}.

\begin{agdasnippet}
\addtolength{\leftskip}{\parindent}
\ExecuteMetaData[Generic/Fusion.tex]{appendR}
\end{agdasnippet}
We finally arrive at the constraints focusing on the semantical counterparts
of the terms' constructors. Each constraint essentially states that evaluating
a term with \AB{𝓢ᴬ}, reifying the result and running \AB{𝓢ᴮ} is equivalent to
using \AB{𝓢ᴬᴮ} straight away. This can be made formal by defining the following
relation \AF{𝓡}.

\begin{agdasnippet}
\addtolength{\leftskip}{\parindent}
\ExecuteMetaData[Generic/Fusion.tex]{crel}
\end{agdasnippet}
When evaluating a variable, on the one hand \AB{𝓢ᴬ}
will look up its meaning in the evaluation environment, turn the resulting value into
a computation which will get reified and then the result will be evaluated with \AB{𝓢ᴮ}.
Provided that all three evaluation environments are related by \AB{𝓔ᴿ} this should
be equivalent to looking up the value in \AB{𝓢ᴬᴮ}'s environment and turning it into a
computation. Hence the constraint \ARF{varᴿ}:

\begin{agdasnippet}
\addtolength{\leftskip}{\parindent}
\ExecuteMetaData[Generic/Fusion.tex]{varR}
\end{agdasnippet}
The case of the algebra follows a similar idea albeit being more complex:
a term gets evaluated using \AB{𝓢ᴬ} and to be able to run \AB{𝓢ᴮ}
afterwards we need to recover a piece of syntax. This is possible if the
\AF{Kripke} functional spaces are reified by being fed placeholder \AB{𝓥ᴬ} arguments
(which can be manufactured thanks to the \ARF{vl\^{𝓥ᴬ}} we mentioned before) and
then quoted. Provided that the result of running \AB{𝓢ᴮ} on that term is
related via \AF{⟦} \AB{d} \AF{⟧ᴿ} (\AF{Kripkeᴿ} \AB{𝓥ᴿ} \AB{𝓒ᴿ}) to the result
of running \AB{𝓢ᴬᴮ} on the original term, the \ARF{algᴿ} constraint states
that the two evaluations yield related computations.

\begin{agdasnippet}
\addtolength{\leftskip}{\parindent}
\ExecuteMetaData[Generic/Fusion.tex]{algR}
\end{agdasnippet}

\subsubsection{The fundamental lemma of fusion}

This set of constraints is enough to prove a fundamental lemma of \AR{Fusion}
stating that from a triple of related environments, one gets a pair of related
computations: the composition of \AB{𝓢ᴬ} and \AB{𝓢ᴮ} on one hand and
\AB{𝓢ᴬᴮ} on the other. This lemma is once again proven mutually with its
counterpart for \semrec{}'s \AF{body}'s action on \AR{Scope}s.
% and the \AD{Size} indices make the proof modular.

\begin{agdasnippet}
 \ExecuteMetaData[Generic/Fusion.tex]{fusiontype}
%\caption{Fundamental Lemma of \AR{Fusion}\label{defn:Fusion}}
\end{agdasnippet}

\subsubsection{Instances of fusion}

A direct consequence of this result is the four lemmas collectively stating
that any pair of renamings and / or substitutions can be fused together to
produce either a renaming (in the renaming-renaming interaction case) or a
substitution (in all the other cases). One such example is the fusion of
substitution followed by renaming into a single substitution where the
renaming has been applied to the environment.

\begin{agdasnippet}
 \ExecuteMetaData[Generic/Fusion/Syntactic.tex]{subren}
%\caption{A Corollary: Substitution-Renaming Fusion\label{defn:SubRen-Fusion}}
\end{agdasnippet}

Another corollary of the fundamental lemma of fusion is the observation that
Kaiser, Schäfer, and Stark~\citeyear{Kaiser-wsdebr} make: \emph{assuming
functional extensionality}, all the ACMM~\citeyear{allais2017type} traversals
are compatible with variable renaming.
We reproduced this result generically for all syntaxes (see accompanying code).
The need for functional extensionality arises in the proof when dealing with
subterms which have extra bound variables. These terms are interpreted as
Kripke functional spaces in the host language and we can only prove that they
take equal inputs to equal outputs. An intensional notion of equality will
simply not do here.
As a consequence, we refrain from using the generic result in practice when
an axiom-free alternative is provable. Kaiser, Schäfer and Stark's observation
naturally raises the question of whether the same semantics are also stable
under substitution. Our semantics implementing printing with names is a clear
counterexample.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% BISIMILARITY

\subsection{Definition of bisimilarity for cofinite objects}

Although we were able to use propositional equality when studying
syntactic traversals working on terms, it is not the appropriate
notion of equality for cofinite trees. What we want is a generic
coinductive notion of bisimilarity for all cofinite tree types
obtained as the unfolding of a description. Two trees are bisimilar
if their top layers have the same shape and their substructures are
themselves bisimilar. This is precisely the type of relation \AF{⟦\_⟧ᴿ}
was defined to express. Hence the following coinductive relation.

\begin{agdasnippet}
 \ExecuteMetaData[Generic/Bisimilar.tex]{bisim}
%\caption{Generic Notion of Bisimilarity for Co-finite Trees\label{defn:bisimilar}}
\end{agdasnippet}

We can then prove by coinduction that this generic definition always gives
rise to an equivalence relation using the relator's stability properties
(if \AB{R} is reflexive / symmetric / transitive then so is {(\AF{⟦} \AB{d} \AF{⟧ᴿ} \AB{R})}
mentioned in Section~\ref{lem:zipstable}.

\begin{agdasnippet}
%\begin{figure}[h]
 \ExecuteMetaData[Generic/Bisimilar.tex]{eqrel}
% \caption{Bisimilarity is an Equivalence Relation}
% \end{figure}
\end{agdasnippet}

This definition can be readily deployed to prove, for example, that the unfolding
of \AF{01↺} defined in Section~\ref{def:colist} is indeed bisimilar to \AF{01⋯}
which was defined in direct style. The proof is straightforward due to the simplicity
of this example: the first \AIC{refl} witnesses the fact that both definitions
pick the same constructor (a cons cell), the second that they carry the
same natural number, and we can conclude by an appeal to the coinduction
hypothesis.

\begin{agdasnippet}
%\begin{figure}[h]
\ExecuteMetaData[Generic/Examples/Colist.tex]{bisim01}
%\caption{The unfolding of \AF{01↺} is bisimilar to the direct-style \AF{01⋯}}
%\end{figure}
\end{agdasnippet}


%\section{Fully Worked-out Example}
%\todo{system F, etc.}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% RELATED WORK

\section{Related work}\label{section:related-work}

\subsection{Variable binding} The representation of variable binding
in formal systems has been a hot topic for decades. Part of the purpose
of the first POPLMark challenge~\citeyear{poplmark} was to explore and
compare various methods.

Having based our work on a de Bruijn encoding of variables, and thus a
canonical treatment of \(\alpha\)-equivalence classes, our work has no
direct comparison with permutation-based treatments such as those of
Pitts' and Gabbay's nominal syntax~\citeyear{gabbay:newaas-jv}.

Our generic universe of syntax is based on
scoped and typed de Bruijn indices~\cite{de1972lambda} but it is not
a necessity. It is for instance possible to give an interpretation
of \AD{Desc}riptions corresponding to Chlipala's Parametric Higher-Order
Abstract Syntax~\citeyear{DBLP:conf/icfp/Chlipala08} and we would be interested
to see what the appropriate notion of \AD{Semantics} is for this representation.

\subsection{Alternative binding structures} The binding structure we
present here is based on a flat, lexical scoping strategy. There are
other strategies and it would be interesting to see whether
our approach could be reused in these cases.

Weirich, Yorgey, and Sheard's work~\citeyear{DBLP:conf/icfp/WeirichYS11}
encompassing a large array of patterns (nested, recursive, telescopic, and
n-ary) can inform our design. They do not enforce scoping invariants internally
which forces them to introduce separate constructors for a simple binder, a
recursive one, or a telescopic pattern. They recover guarantees by giving
their syntaxes a nominal semantics thus bolting down the precise meaning of
each combinator and then proving that users may only generate well formed
terms.

Bach Poulsen, Rouvoet, Tolmach, Krebbers and Visser~\citeyear{BachPoulsen}
introduce notions of scope graphs and frames to scale the techniques typical
of well scoped and typed deep embeddings to imperative languages.
They showcase the core ideas of their work using STLC extended with references
and then demonstrate that they can already handle a large subset of Middleweight
Java.
We have demonstrated that our framework could be used to define effectful
semantics by choosing an appropriate monad stack~\cite{DBLP:journals/iandc/Moggi91}.
This suggests we should be able to model STLC+Ref. It is however clear that
the scoping structures handled by scope graphs and frames are, in their full
generality, out of reach for our framework. In constrast, our work shines by
its generality: we define an entire universe of syntaxes and provide users
with traversals and lemmas implemented \emph{once and for all}.

Many other opportunities to enrich the notion of binder in our library are
highlighted by Cheney~\citeyear{DBLP:conf/icfp/Cheney05a}. As we have demonstrated
in Sections~\ref{section:letbinding} and \ref{section:inlining} we can already
handle let bindings generically for all syntaxes. We are currently considering
the modification of our system to handle deeply nested patterns by removing the
constraint that the binders' and variables' sorts are identical. A notion of
binding corresponding to hierarchical namespaces would be an exciting addition.

We have demonstrated how to write generic programs over the potentially
cyclic structures of Ghani, Hamana, Uustalu and Vene~\citeyear{ghani2006representing}.
Further work by Hamana~\citeyear{Hamana2009} yielded a different presentation
of cyclic structures which preserves sharing: pointers can not only refer
to nodes above them but also across from them in the cyclic tree. Capturing
this class of inductive types as a set of syntaxes with binding and writing
generic programs over them is still an open problem.

\subsection{Semantics of syntaxes with binding} An early foundational study
of a general \emph{semantic} framework for signatures with binding, algebras
for such signatures, and initiality of the term algebra, giving rise to a
categorical ``program'' for substitution and proofs of its properties, was given
by Fiore, Plotkin and Turi~\cite{FiorePlotkinTuri99}. They worked in the category of presheaves
over renamings, (a skeleton of) the category of finite sets. The presheaf
condition corresponds to our notion of being \AF{Thinnable}. Exhibiting
algebras based on both de Bruijn \emph{level} and \emph{index} encodings,
their approach isolates the usual (abstract) arithmetic required of such encodings.

By contrast, we are working in an \emph{implemented} type theory where the
encoding can be understood as its own foundation without appeal to an external
mathematical semantics. We are able to go further in developing machine-checked
such implementations and proofs, themselves generic with respect to an abstract syntax
\AD{Desc} of syntaxes with binding. Moreover, the usual source of implementation
anxiety, namely concrete arithmetic on de Bruijn indices, has been successfully
encapsulated via the \AF{□} coalgebra structure. It is perhaps noteworthy that
our type-theoretic constructions, by contrast with their categorical ones,
appear to make fewer commitments as to functoriality, thinnability, etc. in our
specification of semantics, with such properties typically being \emph{provable}
as a further instance of our framework.

\subsection{Meta-theory automation via tactics and code generation} The
tediousness of repeatedly
proving similar statements has unsurprisingly led to various attempts at
automating the pain away via either code generation or the definition of
tactics. These solutions can be seen as untrusted oracles driving the
interactive theorem prover.

Polonowski's DBGen~\citeyear{polonowski:db} takes as input a raw syntax with
comments annotating binding sites. It generates a module defining lifting,
substitution as well as a raw syntax using names and a validation function
transforming named terms into de Bruijn ones; we refrain from calling it a
scope checker as terms are not statically proven to be well scoped.

Kaiser, Schäfer, and Stark~\citeyear{Kaiser-wsdebr} build on our previous paper
to draft possible theoretical foundations for Autosubst, a so-far untrusted
set of tactics. The paper is based on a specific syntax: well scoped call-by-value
System F. In contrast, our effort has been here to carve out
a precise universe of syntaxes with binding and give a systematic account
of these syntaxes' semantics and proofs.

Keuchel, Weirich, and Schrijvers' Needle~\citeyear{needleandknot} is a code
generator written in Haskell producing syntax-specific Coq modules
implementing common traversals and lemmas about them.

\subsection{Universes of syntaxes with binding} Keeping in mind Altenkirch
and McBride's observation that generic programming is everyday programming
in dependently typed languages~\citeyear{DBLP:conf/ifip2-1/AltenkirchM02}, we can naturally
expect generic, provably sound, treatments of these notions in tools such as
Agda or Coq.

Keuchel~\citeyear{Keuchel:Thesis:2011} together with Jeuring~\citeyear{DBLP:conf/icfp/KeuchelJ12}
define a universe of syntaxes with binding with a rich notion of binding patterns
closed under products but also sums as long as the disjoint patterns bind the same
variables. They give their universe two distinct semantics: a first one based on well
scoped de Bruijn indices and a second one based on Parametric Higher-Order Abstract
Syntax (PHOAS)~\cite{DBLP:conf/icfp/Chlipala08} together with a generic conversion
function from the de Bruijn syntax to the PHOAS one. Following McBride's unpublished 2005 manuscript, which emerged as \cite{benton2012strongly},
they implement both renaming and substitution in one fell swoop. They leave other
opportunities for generic programming and proving to future work.

Keuchel, Weirich, and Schrijvers' Knot~\citeyear{needleandknot} implements
as a set of generic programs the traversals and lemmas generated in specialised
forms by their Needle program. They see Needle as a pragmatic choice: working
directly with the free monadic terms over finitary containers would be too cumbersome. In
our experience solving the POPLMark Reloaded challenge, Agda's pattern
synonyms make working with an encoded definition almost
seamless.

The GMeta generic framework~\citeyear{gmeta} provides a universe of syntaxes
and offers various binding conventions (locally nameless~\cite{Chargueraud2012}
or de Bruijn indices). It also generically implements common traversals (e.g. computing
the sets of free variables,
% measuring the size of a term,
shifting
de Bruijn indices or substituting terms for parameters) as well as common
predicates (e.g. being a closed term) and provides generic lemmas proving that
they are well behaved. It does not offer a generic framework
for defining new well scoped-and-typed semantics and proving their properties.

Érdi~\citeyear{gergodraft} defines a universe inspired by a first draft of this
paper and gives three different interpretations (raw, scoped and typed syntax)
related via erasure. He provides type- and scope-preserving renaming and
substitution as well as various generic proofs that they are well behaved but
offers neither a generic notion of semantics, nor generic proof frameworks.

Copello~\citeyear{copello2017} works with \emph{named} binders and
defines nominal techniques (e.g. name swapping) and ultimately $\alpha$-equivalence
over a universe of regular trees with binders inspired by Morris'~\citeyear{morris-regulartt}.

\subsection{Fusion of successive traversals}

The careful characterisation of the successive recursive traversals which can be
fused together into a single pass in a semantics-preserving way is not new. This
transformation is a much needed optimisation principle in a high-level functional
language.

Through the careful study of the recursion operator associated to each
strictly positive data type,
Malcolm~\citeyear{DBLP:journals/scp/Malcolm90} defined optimising
fusion proof principles.
%
Other optimisations such as deforestation~\cite{DBLP:journals/tcs/Wadler90}
or the compilation of a recursive definition into an equivalent abstract
machine-based tail-recursive program~\cite{DBLP:conf/icfp/CortinasS18}
rely on similar generic proofs that these transformations are meaning-preserving.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% CONCLUSION

\section{Conclusion and future work}

Recalling our earlier work~\citeyear{allais2017type}
we have started from an example of a type- and scope-safe language (the simply typed
λ-calculus), have studied common invariant preserving traversals and noticed their
similarity. After introducing a notion of semantics and refactoring these traversals as
instances of the same fundamental lemma, we have observed the tight
connection between the abstract definition of semantics and the shape of the
language.

By extending a universe of data type descriptions to support a notion of binding,
we have given a generic presentation of syntaxes with binding. We then described
a large class of type- and scope-safe generic programs acting on all of them.
We started with syntactic traversals such as renaming and substitution. We then
demonstrated how to write a small compiler pipeline: scope checking, type checking
and elaboration to a core language, desugaring of new constructors added by a language
transformer, dead code elimination and inlining, partial evaluation, and printing
with names.

We have seen how to construct generic proofs about these generic programs. We
first introduced a Simulation relation showing what it means for two semantics
to yield related outputs whenever they are fed related input environments. We
then built on our experience to tackle a more involved case: identifying a set
of constraints guaranteeing that two semantics run consecutively can be subsumed
by a single pass of a third one.

We have put all of these results into practice using them to solve the (to be
published) POPLMark Reloaded challenge %%%\citeyear{{abel_allais_hameer_pientka_momigliano_schäfer_stark_2019}
which consists of formalising strong
normalisation for the simply typed λ-calculus via a logical relation
argument. This also gave us the opportunity to try our framework on larger
languages by tackling the challenge's extensions to sum types and G\"{o}del's
System T.

Finally, we have demonstrated that this formalisation can be reused
in other domains by seeing our syntaxes with binding as potentially cyclic
terms. Their unfolding is a non-standard semantics and we provide the
user with a generic notion of bisimilarity to reason about them.

\subsection{Limitations of the current framework}

Although quite versatile already our current framework has some limitations
which suggest avenues for future work. We list these limitations from easiest
to hardest to resolve. Remember that each modification to the universe of
syntaxes needs to be given an appropriate semantics.

\paragraph*{Closure under products} Our current universe of descriptions is
closed under sums as demonstrated in Section~\ref{desccomb}. It is however
not closed under products: two arbitrary right-nested products conforming
to a description may disagree on the sort of the term they are constructing.
An approach where the sort is an input from which the description of allowed
constructors is computed (à la Dagand \citeyear{DBLP:phd/ethos/Dagand13} where,
for instance, the \AIC{`lam} constructor is only offered if the input sort is
a function type) would not suffer from this limitation.

\paragraph*{Unrestricted variables} Our current notion of variable can be used
to form a term of any sort. We remarked in Sections~\ref{section:typechecking}
and \ref{section:elaboration} that in some languages we want to restrict this
ability to one sort in particular. In that case, we wanted users to only be able
to use variables at the sort \AIC{Infer} of our bidirectional language. For the
time-being we made do by restricting the environment values our \AR{Semantics}
use to a subset of the sorts: terms with variables of the wrong sort will not be
given a semantics.

\paragraph*{Flat binding structure} Our current set-up limits us to flat binding
structures: variables and binders share the same sorts. This prevents us from
representing languages with binding patterns, for instance pattern-matching
let binders which can have arbitrarily nested patterns taking pairs apart.

\paragraph*{Closure under derivation} One-hole contexts play a major role in the
theory of programming languages. Just like the one-hole context of a data type is
a data type~\cite{DBLP:journals/fuin/AbbottAMG05}, we would like our universe to
be closed under derivatives so that the formalisation of, for example, evaluation contexts
could benefit directly from the existing machinery.

\paragraph*{Closure under closures} Jander's work on formalising and certifying
continuation-passing style transformations~\cite{Jander:Thesis:2019}
highlighted the need for a notion of syntaxes with closures. Recalling
that our notion of Semantics is always compatible with precomposition
with a renaming~\cite{Kaiser-wsdebr} but not necessarily
precomposition with a substitution (printing is, for instance, not
stable under substitution), accommodating terms with suspended
substitutions is a real challenge. Preliminary experiments show that a
drastic modification of the type of the fundamental lemma of
\AR{Semantics} makes dealing with such closures possible. Whether the
resulting traversal has good properties that can be proven generically
is still an open problem.

\subsection{Future work}

The diverse influences leading to this work suggest many opportunities for
future research.

\begin{itemize}
\item Our example of the elaboration of an enriched language to a core
  one, ACMM's implementation of a continuation-passing style
  conversion function, and Jander's work~\citeyear{Jander:Thesis:2019}
  on the certification of a intrinsically typed CPS transformation
  raises the question of how many such common compilation passes can
  be implemented generically.
\item Our universe only includes syntaxes that allow unrestricted
  variable use. Variables may be used multiple times or never, with no
  restriction. We are interested in representing syntaxes that only
  allow single use of variables, such as term calculi for linear logic
  \cite{DBLP:conf/tlca/BentonBPH93,barber96dual,context-constrained},
  or that annotate variables with usage information
  \cite{BrunelGMZ14,GhicaS14,PetricekOM14}, or arrange variables into
  non-list-like structures such as bunches
  \cite{DBLP:journals/jfp/OHearn03}, or arbitrary algebraic structures
  \cite{DBLP:conf/rta/LicataSR17}, and in investigating what form a
  generic semantics for these syntaxes takes.
\item An extension of Dagand and McBride's theory of
  ornaments~\citeyear{DBLP:journals/jfp/DagandM14} could provide an
  appropriate framework to formalise and mechanise the connection
  between various languages, some being seen as refinements of
  others. This is particularly evident when considering the
  informative type checker (see the accompanying code) which given a
  scoped term produces a scoped-and-typed term by type checking or
  type inference.
\item Our work on the POPLMark Reloaded challenge highlights a need
  for generic notions of congruence closure which would come with
  guarantees (if the original relation is stable under renaming and
  substitution so should the closure).  Similarly, the ``evaluation
  contexts'' corresponding to a syntax could be derived automatically
  by building on the work of Huet~\citeyear{huet_1997} and Abbott,
  Altenkirch, McBride and
  Ghani~\citeyear{DBLP:journals/fuin/AbbottAMG05}, allowing us to
  revisit previous work based on concrete instances of ACMM such as
  McLaughlin, McKinna and Stark~\citeyear{craig2018triangle}.
\end{itemize}

We now know how to generically describe syntaxes and their well
behaved semantics. We can now start asking what it means to define
well behaved judgments. Why stop at helping the user write their
specific language's meta-theory when we could study meta-meta-theory?
